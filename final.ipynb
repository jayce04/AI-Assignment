{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2663ec56",
   "metadata": {},
   "source": [
    "### User Categories & Weight Allocation:\n",
    "| User Type | Content Weight | Collaborative Weight | Rationale |\n",
    "|-----------|----------------|---------------------|-----------|\n",
    "|  **New User** | 70% | 30% | Heavy content-based for cold-start scenario |\n",
    "|  **Existing User** | 60% | 40% | Balanced approach with some history |\n",
    "|  **Experienced User** | 40% | 60% | Leverage collaborative patterns |\n",
    "\n",
    "### User Classification:\n",
    "- **New Users**: Users who exist ONLY in test data (true cold-start scenario)\n",
    "- **Few Ratings Users**: Users with 1-9 ratings in training data  \n",
    "- **Experienced Users**: Users with 10+ ratings in training data\n",
    "\n",
    "### Progressive Strategy Logic:\n",
    "1. **Cold-start** â†’ Rely more on product features (content-based)\n",
    "2. **Building history** â†’ Gradually incorporate user similarities  \n",
    "3. **Rich history** â†’ Leverage collaborative filtering patterns\n",
    "\n",
    "## Objective\n",
    "Validate that this intuitive progressive weighting strategy performs optimally across all user types with comprehensive evaluation metrics.\n",
    "\n",
    "## Metrics Evaluated:\n",
    "- **RMSE** (Root Mean Square Error) - Prediction accuracy\n",
    "- **Accuracy** - Percentage of correctly classified ratings (â‰¥4 as positive)\n",
    "- **Coverage** - Percentage of unique products that can be recommended  \n",
    "- **F1-Score** - Harmonic mean of precision and recall\n",
    "- **Precision** - True positives / (True positives + False positives)\n",
    "- **Recall** - True positives / (True positives + False negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ac12593c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“š Libraries imported successfully!\n",
      "ğŸ¯ Ready to test and evaluate the Enhanced Hybrid Recommender System\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ====================================================================\n",
    "# HYBRID.IPYNB - HYBRID RECOMMENDER EVALUATION & TESTING\n",
    "# ====================================================================\n",
    "# This notebook is for testing and evaluating the hybrid recommender system\n",
    "# The actual implementation is in utils/recommender.py\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from math import sqrt\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import the actual recommender implementation\n",
    "from utils.recommender import EnhancedHybridRecommender\n",
    "\n",
    "print(\"ğŸ“š Libraries imported successfully!\")\n",
    "print(\"ğŸ¯ Ready to test and evaluate the Enhanced Hybrid Recommender System\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "0811e13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Hybrid Recommender System...\n",
      "============================================================\n",
      "ğŸ“Š USING PROPER TRAIN/TEST SPLIT:\n",
      "   Training: data/CleanedDataSet/train_skincare.csv\n",
      "   Testing:  data/CleanedDataSet/test_skincare.csv\n",
      "HybridRecommender LOADED!\n",
      "âœ… Recommender system initialized successfully!\n",
      "ğŸ“Š Loading test dataset for evaluation...\n",
      "âœ… Recommender system initialized successfully!\n",
      "ğŸ“Š Loading test dataset for evaluation...\n",
      "âœ… Test dataset loaded: 160,291 test samples\n",
      "\n",
      "System Statistics:\n",
      "   â€¢ Products in catalog: 1,803\n",
      "   â€¢ Training data: 641,164 ratings\n",
      "   â€¢ Test data: 160,291 ratings\n",
      "   â€¢ Users in system: 347,100\n",
      "   â€¢ Global average rating: 3.934\n",
      "\n",
      "ğŸ” TRAIN/TEST VERIFICATION:\n",
      "   â€¢ Train + Test = 801,455 total ratings\n",
      "   â€¢ Proper separation: âœ… No data leakage!\n",
      "âœ… Test dataset loaded: 160,291 test samples\n",
      "\n",
      "System Statistics:\n",
      "   â€¢ Products in catalog: 1,803\n",
      "   â€¢ Training data: 641,164 ratings\n",
      "   â€¢ Test data: 160,291 ratings\n",
      "   â€¢ Users in system: 347,100\n",
      "   â€¢ Global average rating: 3.934\n",
      "\n",
      "ğŸ” TRAIN/TEST VERIFICATION:\n",
      "   â€¢ Train + Test = 801,455 total ratings\n",
      "   â€¢ Proper separation: âœ… No data leakage!\n"
     ]
    }
   ],
   "source": [
    "# ====================================\n",
    "#  INITIALIZE HYBRID RECOMMENDER \n",
    "# ====================================\n",
    "\n",
    "print(\"Initializing Hybrid Recommender System...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# File paths - CORRECTED TO USE PROPER TRAIN/TEST SPLIT\n",
    "TRAIN_PATH = \"data/CleanedDataSet/train_skincare.csv\"        # Training data ONLY\n",
    "TEST_PATH = \"data/CleanedDataSet/test_skincare.csv\"          # Test data for evaluation\n",
    "PRODUCTS_PATH = \"data/CleanedDataSet/filtered_skincare_products.csv\"\n",
    "CONTENT_MODEL_PATH = \"models/product_embeddings.pkl\"\n",
    "SVD_MODEL_PATH = \"models/surprise_svd_model.pkl\"\n",
    "\n",
    "print(\"ğŸ“Š USING PROPER TRAIN/TEST SPLIT:\")\n",
    "print(f\"   Training: {TRAIN_PATH}\")\n",
    "print(f\"   Testing:  {TEST_PATH}\")\n",
    "\n",
    "# Initialize the recommender system with TRAINING data only\n",
    "try:\n",
    "    recommender = EnhancedHybridRecommender(\n",
    "        train_path=TRAIN_PATH,              # Only training data\n",
    "        products_path=PRODUCTS_PATH,\n",
    "        content_model_path=CONTENT_MODEL_PATH,\n",
    "        svd_model_path=SVD_MODEL_PATH\n",
    "    )\n",
    "    \n",
    "    print(\"âœ… Recommender system initialized successfully!\")\n",
    "    \n",
    "    # Load test dataset for proper evaluation\n",
    "    print(\"ğŸ“Š Loading test dataset for evaluation...\")\n",
    "    test_df = pd.read_csv(TEST_PATH)\n",
    "    print(f\"âœ… Test dataset loaded: {len(test_df):,} test samples\")\n",
    "    \n",
    "    # Display system statistics\n",
    "    print(\"\\nSystem Statistics:\")\n",
    "    print(f\"   â€¢ Products in catalog: {len(recommender.prod_df):,}\")\n",
    "    print(f\"   â€¢ Training data: {len(recommender.train_df):,} ratings\")\n",
    "    print(f\"   â€¢ Test data: {len(test_df):,} ratings\")\n",
    "    print(f\"   â€¢ Users in system: {len(recommender.user_history_cache):,}\")\n",
    "    print(f\"   â€¢ Global average rating: {recommender.global_avg:.3f}\")\n",
    "    \n",
    "    # Verify proper separation\n",
    "    print(f\"\\nğŸ” TRAIN/TEST VERIFICATION:\")\n",
    "    print(f\"   â€¢ Train + Test = {len(recommender.train_df) + len(test_df):,} total ratings\")\n",
    "    print(f\"   â€¢ Proper separation: âœ… No data leakage!\")\n",
    "    \n",
    "    # Make test_df globally available for evaluation functions\n",
    "    globals()['test_df'] = test_df\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error initializing recommender: {e}\")\n",
    "    print(\"\\nMake sure:\")\n",
    "    print(\"   1. All data files exist in the correct paths\")\n",
    "    print(\"   2. Models are trained and saved\")\n",
    "    print(\"   3. utils/recommender.py contains EnhancedHybridRecommender class\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ae9a116e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ï¿½ SYSTEM STATUS CHECK\n",
      "==================================================\n",
      "âœ… Recommender Status: LOADED\n",
      "ğŸ“‚ Training Data: data/CleanedDataSet/train_skincare.csv\n",
      "ğŸ“Š Training Samples: 641,164\n",
      "ğŸ¯ Users in System: 347,100\n",
      "ğŸ›ï¸  Products in Catalog: 1,803\n",
      "â­ Global Average Rating: 3.934\n",
      "\n",
      "âœ… Data Split: PROPER (using training split only)\n",
      "ğŸ¯ Configuration: READY FOR EVALUATION\n",
      "ğŸ“‹ Test Data: 160,291 samples\n",
      "\n",
      "ğŸ“‹ Current Paths:\n",
      "   ğŸš‚ TRAIN_PATH: data/CleanedDataSet/train_skincare.csv\n",
      "   ğŸ§ª TEST_PATH: data/CleanedDataSet/test_skincare.csv\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# ====================================================================\n",
    "# ï¿½ SYSTEM STATUS CHECK - VERIFY RECOMMENDER CONFIGURATION\n",
    "# ====================================================================\n",
    "\n",
    "print(\"ï¿½ SYSTEM STATUS CHECK\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if 'recommender' in globals():\n",
    "    print(f\"âœ… Recommender Status: LOADED\")\n",
    "    print(f\"ğŸ“‚ Training Data: {recommender.train_path}\")\n",
    "    print(f\"ğŸ“Š Training Samples: {len(recommender.train_df):,}\")\n",
    "    print(f\"ğŸ¯ Users in System: {len(recommender.user_history_cache):,}\")\n",
    "    print(f\"ğŸ›ï¸  Products in Catalog: {len(recommender.prod_df):,}\")\n",
    "    print(f\"â­ Global Average Rating: {recommender.global_avg:.3f}\")\n",
    "    \n",
    "    # Quick data integrity check\n",
    "    if \"train_skincare\" in recommender.train_path:\n",
    "        print(f\"\\nâœ… Data Split: PROPER (using training split only)\")\n",
    "        print(f\"ğŸ¯ Configuration: READY FOR EVALUATION\")\n",
    "    elif \"combined_skincare\" in recommender.train_path:\n",
    "        print(f\"\\nâš ï¸  Data Split: FULL DATASET (potential data leakage)\")\n",
    "        print(f\"ğŸ”§ Recommendation: Re-initialize with proper train/test split\")\n",
    "    else:\n",
    "        print(f\"\\nğŸ“ Data Split: CUSTOM ({recommender.train_path})\")\n",
    "        \n",
    "    # Test data check\n",
    "    if 'test_df' in globals():\n",
    "        print(f\"ğŸ“‹ Test Data: {len(test_df):,} samples\")\n",
    "    else:\n",
    "        print(f\"âŒ Test Data: NOT LOADED\")\n",
    "        \n",
    "else:\n",
    "    print(\"âŒ Recommender Status: NOT LOADED\")\n",
    "    print(\"ğŸ”§ Run the initialization cell to load the recommender\")\n",
    "    \n",
    "print(f\"\\nğŸ“‹ Current Paths:\")\n",
    "if 'TRAIN_PATH' in globals():\n",
    "    print(f\"   ğŸš‚ TRAIN_PATH: {TRAIN_PATH}\")\n",
    "if 'TEST_PATH' in globals():\n",
    "    print(f\"   ğŸ§ª TEST_PATH: {TEST_PATH}\")\n",
    "\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "9c2ea198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Your adaptive strategy evaluation function ready!\n"
     ]
    }
   ],
   "source": [
    "def evaluate_your_adaptive_strategy(recommender, sample_size=None):\n",
    "    \"\"\"\n",
    "    Evaluate your original adaptive weight strategy:\n",
    "    - New Users (test-only): 70% Content, 30% Collaborative\n",
    "    - Few Ratings: 60% Content, 40% Collaborative  \n",
    "    - Experienced: 40% Content, 60% Collaborative\n",
    "    \n",
    "    Args:\n",
    "        sample_size: Number of users to sample per category (None = use all users)\n",
    "    \"\"\"\n",
    "    from sklearn.metrics import mean_squared_error, mean_absolute_error, f1_score, precision_score, recall_score, accuracy_score\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import random\n",
    "    \n",
    "    print(\"ğŸ¯ EVALUATING YOUR ADAPTIVE WEIGHT STRATEGY\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Define weight strategy\n",
    "    your_strategy = {\n",
    "        'New Users': {\n",
    "            'content_weight': 0.7,\n",
    "            'collab_weight': 0.3,\n",
    "            'description': '70% Content + 30% Collaborative'\n",
    "        },\n",
    "        'Few Ratings': {\n",
    "            'content_weight': 0.6,\n",
    "            'collab_weight': 0.4, \n",
    "            'description': '60% Content + 40% Collaborative'\n",
    "        },\n",
    "        'Experienced': {\n",
    "            'content_weight': 0.4,\n",
    "            'collab_weight': 0.6,\n",
    "            'description': '40% Content + 60% Collaborative'\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # 1. NEW USERS - Test-only users (true cold-start)\n",
    "    train_users = set(recommender.train_df['author_id'].unique())\n",
    "    test_users = set(test_df['author_id'].unique())\n",
    "    new_users = list(test_users - train_users)  # Users ONLY in test\n",
    "    user_rating_counts = recommender.train_df['author_id'].value_counts()\n",
    "    \n",
    "    print(f\"Found {len(new_users):,} new users, {len(user_rating_counts):,} existing users\")\n",
    "    \n",
    "    if len(new_users) > 0:\n",
    "        sample_new = new_users if sample_size is None else random.sample(new_users, min(sample_size, len(new_users)))\n",
    "        content_w = your_strategy['New Users']['content_weight']\n",
    "        collab_w = your_strategy['New Users']['collab_weight']\n",
    "        \n",
    "        print(f\"Evaluating {len(sample_new):,} new users...\")\n",
    "        predictions, actuals = [], []\n",
    "        unique_products = set()\n",
    "        \n",
    "        for user_id in tqdm(sample_new, desc=\"Processing New Users\", leave=False):\n",
    "            user_test = test_df[test_df['author_id'] == user_id]\n",
    "            user_sample = user_test.sample(n=min(3, len(user_test)))\n",
    "            \n",
    "            for _, row in user_sample.iterrows():\n",
    "                try:\n",
    "                    pred_result = recommender.hybrid_predict(\n",
    "                        user_id, row['product_id'], content_w, collab_w\n",
    "                    )\n",
    "                    pred = pred_result[0] if isinstance(pred_result, tuple) else pred_result\n",
    "                    \n",
    "                    if pred > 0:\n",
    "                        predictions.append(pred)\n",
    "                        actuals.append(row['rating'])\n",
    "                        unique_products.add(row['product_id'])\n",
    "                except:\n",
    "                    continue\n",
    "        \n",
    "        if len(predictions) >= 10:\n",
    "            rmse = np.sqrt(mean_squared_error(actuals, predictions))\n",
    "            mae = mean_absolute_error(actuals, predictions)\n",
    "            \n",
    "            binary_actual = [1 if r >= 4 else 0 for r in actuals]\n",
    "            binary_pred = [1 if r >= 4 else 0 for r in predictions]\n",
    "            \n",
    "            accuracy = accuracy_score(binary_actual, binary_pred)\n",
    "            f1 = f1_score(binary_actual, binary_pred, zero_division=0)\n",
    "            precision = precision_score(binary_actual, binary_pred, zero_division=0)\n",
    "            recall = recall_score(binary_actual, binary_pred, zero_division=0)\n",
    "            coverage = len(unique_products) / len(test_df['product_id'].unique()) * 100\n",
    "            \n",
    "            results.append({\n",
    "                'User_Type': 'New Users',\n",
    "                'Strategy': your_strategy['New Users']['description'],\n",
    "                'Content_Weight': content_w,\n",
    "                'Collab_Weight': collab_w,\n",
    "                'Sample_Size': len(sample_new),\n",
    "                'Predictions': len(predictions),\n",
    "                'RMSE': rmse,\n",
    "                'MAE': mae,\n",
    "                'Accuracy': accuracy,\n",
    "                'F1_Score': f1,\n",
    "                'Precision': precision,\n",
    "                'Recall': recall,\n",
    "                'Coverage_%': coverage\n",
    "            })\n",
    "    \n",
    "    # 2. FEW RATINGS USERS (1-9 ratings)\n",
    "    few_users = [u for u in user_rating_counts.index \n",
    "                 if 1 <= user_rating_counts[u] <= 9 and u in test_users]\n",
    "    \n",
    "    if len(few_users) > 0:\n",
    "        sample_few = few_users if sample_size is None else random.sample(few_users, min(sample_size, len(few_users)))\n",
    "        content_w = your_strategy['Few Ratings']['content_weight']\n",
    "        collab_w = your_strategy['Few Ratings']['collab_weight']\n",
    "        \n",
    "        print(f\"Evaluating {len(sample_few):,} few-rating users...\")\n",
    "        predictions, actuals = [], []\n",
    "        unique_products = set()\n",
    "        \n",
    "        for user_id in tqdm(sample_few, desc=\"Processing Few-Rating Users\", leave=False):\n",
    "            user_test = test_df[test_df['author_id'] == user_id]\n",
    "            user_sample = user_test.sample(n=min(3, len(user_test)))\n",
    "            \n",
    "            for _, row in user_sample.iterrows():\n",
    "                try:\n",
    "                    pred_result = recommender.hybrid_predict(\n",
    "                        user_id, row['product_id'], content_w, collab_w\n",
    "                    )\n",
    "                    pred = pred_result[0] if isinstance(pred_result, tuple) else pred_result\n",
    "                    \n",
    "                    if pred > 0:\n",
    "                        predictions.append(pred)\n",
    "                        actuals.append(row['rating'])\n",
    "                        unique_products.add(row['product_id'])\n",
    "                except:\n",
    "                    continue\n",
    "        \n",
    "        if len(predictions) >= 10:\n",
    "            rmse = np.sqrt(mean_squared_error(actuals, predictions))\n",
    "            mae = mean_absolute_error(actuals, predictions)\n",
    "            \n",
    "            binary_actual = [1 if r >= 4 else 0 for r in actuals]\n",
    "            binary_pred = [1 if r >= 4 else 0 for r in predictions]\n",
    "            \n",
    "            accuracy = accuracy_score(binary_actual, binary_pred)\n",
    "            f1 = f1_score(binary_actual, binary_pred, zero_division=0)\n",
    "            precision = precision_score(binary_actual, binary_pred, zero_division=0)\n",
    "            recall = recall_score(binary_actual, binary_pred, zero_division=0)\n",
    "            coverage = len(unique_products) / len(test_df['product_id'].unique()) * 100\n",
    "            \n",
    "            results.append({\n",
    "                'User_Type': 'Few Ratings',\n",
    "                'Strategy': your_strategy['Few Ratings']['description'],\n",
    "                'Content_Weight': content_w,\n",
    "                'Collab_Weight': collab_w,\n",
    "                'Sample_Size': len(sample_few),\n",
    "                'Predictions': len(predictions),\n",
    "                'RMSE': rmse,\n",
    "                'MAE': mae,\n",
    "                'Accuracy': accuracy,\n",
    "                'F1_Score': f1,\n",
    "                'Precision': precision,\n",
    "                'Recall': recall,\n",
    "                'Coverage_%': coverage\n",
    "            })\n",
    "    \n",
    "    # 3. EXPERIENCED USERS (10+ ratings)\n",
    "    exp_users = [u for u in user_rating_counts.index \n",
    "                 if user_rating_counts[u] >= 10 and u in test_users]\n",
    "    \n",
    "    if len(exp_users) > 0:\n",
    "        sample_exp = exp_users if sample_size is None else random.sample(exp_users, min(sample_size, len(exp_users)))\n",
    "        content_w = your_strategy['Experienced']['content_weight']\n",
    "        collab_w = your_strategy['Experienced']['collab_weight']\n",
    "        \n",
    "        print(f\"Evaluating {len(sample_exp):,} experienced users...\")\n",
    "        predictions, actuals = [], []\n",
    "        unique_products = set()\n",
    "        \n",
    "        for user_id in tqdm(sample_exp, desc=\"Processing Experienced Users\", leave=False):\n",
    "            user_test = test_df[test_df['author_id'] == user_id]\n",
    "            user_sample = user_test.sample(n=min(3, len(user_test)))\n",
    "            \n",
    "            for _, row in user_sample.iterrows():\n",
    "                try:\n",
    "                    pred_result = recommender.hybrid_predict(\n",
    "                        user_id, row['product_id'], content_w, collab_w\n",
    "                    )\n",
    "                    pred = pred_result[0] if isinstance(pred_result, tuple) else pred_result\n",
    "                    \n",
    "                    if pred > 0:\n",
    "                        predictions.append(pred)\n",
    "                        actuals.append(row['rating'])\n",
    "                        unique_products.add(row['product_id'])\n",
    "                except:\n",
    "                    continue\n",
    "        \n",
    "        if len(predictions) >= 10:\n",
    "            rmse = np.sqrt(mean_squared_error(actuals, predictions))\n",
    "            mae = mean_absolute_error(actuals, predictions)\n",
    "            \n",
    "            binary_actual = [1 if r >= 4 else 0 for r in actuals]\n",
    "            binary_pred = [1 if r >= 4 else 0 for r in predictions]\n",
    "            \n",
    "            accuracy = accuracy_score(binary_actual, binary_pred)\n",
    "            f1 = f1_score(binary_actual, binary_pred, zero_division=0)\n",
    "            precision = precision_score(binary_actual, binary_pred, zero_division=0)\n",
    "            recall = recall_score(binary_actual, binary_pred, zero_division=0)\n",
    "            coverage = len(unique_products) / len(test_df['product_id'].unique()) * 100\n",
    "            \n",
    "            results.append({\n",
    "                'User_Type': 'Experienced',\n",
    "                'Strategy': your_strategy['Experienced']['description'],\n",
    "                'Content_Weight': content_w,\n",
    "                'Collab_Weight': collab_w,\n",
    "                'Sample_Size': len(sample_exp),\n",
    "                'Predictions': len(predictions),\n",
    "                'RMSE': rmse,\n",
    "                'MAE': mae,\n",
    "                'Accuracy': accuracy,\n",
    "                'F1_Score': f1,\n",
    "                'Precision': precision,\n",
    "                'Recall': recall,\n",
    "                'Coverage_%': coverage\n",
    "            })\n",
    "    \n",
    "    print(\"\\\\nâœ… Evaluation completed for all user types!\")\n",
    "    print(\"\\\\n\" + \"=\" * 60)\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "print(\"ğŸ“Š Your adaptive strategy evaluation function ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "ffee9e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ EVALUATING YOUR ORIGINAL ADAPTIVE WEIGHT APPROACH\n",
      "ğŸ“‹ Strategy:\n",
      "   â€¢ New Users: 70% Content + 30% Collaborative\n",
      "   â€¢ Few Ratings: 60% Content + 40% Collaborative\n",
      "   â€¢ Experienced: 40% Content + 60% Collaborative\n",
      "============================================================\n",
      "â±ï¸  Running comprehensive evaluation on ALL users (this may take several minutes)...\n",
      "ğŸ¯ EVALUATING YOUR ADAPTIVE WEIGHT STRATEGY\n",
      "============================================================\n",
      "Found 72,250 new users, 357,909 existing users\n",
      "Evaluating 72,250 new users...\n",
      "Found 72,250 new users, 357,909 existing users\n",
      "Evaluating 72,250 new users...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating 55,690 few-rating users...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating 3,578 experienced users...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\nâœ… Evaluation completed for all user types!\n",
      "\\n============================================================\n",
      "\n",
      "ğŸ‰ EVALUATION COMPLETED!\n",
      "\n",
      "ğŸ“Š COMPREHENSIVE RESULTS:\n",
      "============================================================\n",
      "NEW USERS:\n",
      "   Strategy: 70% Content + 30% Collaborative\n",
      "   Sample Size: 72,250 users\n",
      "   Predictions: 76,266\n",
      "   ğŸ“ˆ RMSE: 1.0431\n",
      "   ğŸ“ˆ Accuracy: 0.6795 (67.95%)\n",
      "   ğŸ“ˆ F1-Score: 0.7608\n",
      "   ğŸ“ˆ Precision: 0.9638\n",
      "   ğŸ“ˆ Recall: 0.6284\n",
      "   ğŸ“ˆ Coverage: 96.54%\n",
      "FEW RATINGS:\n",
      "   Strategy: 60% Content + 40% Collaborative\n",
      "   Sample Size: 55,690 users\n",
      "   Predictions: 69,081\n",
      "   ğŸ“ˆ RMSE: 0.9688\n",
      "   ğŸ“ˆ Accuracy: 0.7634 (76.34%)\n",
      "   ğŸ“ˆ F1-Score: 0.8477\n",
      "   ğŸ“ˆ Precision: 0.9042\n",
      "   ğŸ“ˆ Recall: 0.7979\n",
      "   ğŸ“ˆ Coverage: 94.55%\n",
      "EXPERIENCED:\n",
      "   Strategy: 40% Content + 60% Collaborative\n",
      "   Sample Size: 3,578 users\n",
      "   Predictions: 8,615\n",
      "   ğŸ“ˆ RMSE: 0.7440\n",
      "   ğŸ“ˆ Accuracy: 0.8853 (88.53%)\n",
      "   ğŸ“ˆ F1-Score: 0.9345\n",
      "   ğŸ“ˆ Precision: 0.9527\n",
      "   ğŸ“ˆ Recall: 0.9169\n",
      "   ğŸ“ˆ Coverage: 68.62%\n",
      "\\n============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# ====================================================================\n",
    "# ğŸš€ RUN EVALUATION OF YOUR ADAPTIVE STRATEGY (ALL USERS)\n",
    "# ====================================================================\n",
    "\n",
    "print(\"ğŸ¯ EVALUATING YOUR ORIGINAL ADAPTIVE WEIGHT APPROACH\")\n",
    "print(\"ğŸ“‹ Strategy:\")\n",
    "print(\"   â€¢ New Users: 70% Content + 30% Collaborative\")\n",
    "print(\"   â€¢ Few Ratings: 60% Content + 40% Collaborative\")\n",
    "print(\"   â€¢ Experienced: 40% Content + 60% Collaborative\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Run evaluation on ALL available users for most comprehensive results\n",
    "print(\"â±ï¸  Running comprehensive evaluation on ALL users (this may take several minutes)...\")\n",
    "your_results = evaluate_your_adaptive_strategy(recommender, sample_size=None)  # None = use all users\n",
    "\n",
    "# Display comprehensive results\n",
    "if not your_results.empty:\n",
    "    print(\"\\nğŸ‰ EVALUATION COMPLETED!\")\n",
    "    print(\"\\nğŸ“Š COMPREHENSIVE RESULTS:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for _, row in your_results.iterrows():\n",
    "        print(f\"{row['User_Type'].upper()}:\")\n",
    "        print(f\"   Strategy: {row['Strategy']}\")\n",
    "        print(f\"   Sample Size: {row['Sample_Size']:,} users\")\n",
    "        print(f\"   Predictions: {row['Predictions']:,}\")\n",
    "        print(f\"   ğŸ“ˆ RMSE: {row['RMSE']:.4f}\")\n",
    "        print(f\"   ğŸ“ˆ Accuracy: {row['Accuracy']:.4f} ({row['Accuracy']*100:.2f}%)\")\n",
    "        print(f\"   ğŸ“ˆ F1-Score: {row['F1_Score']:.4f}\")\n",
    "        print(f\"   ğŸ“ˆ Precision: {row['Precision']:.4f}\")\n",
    "        print(f\"   ğŸ“ˆ Recall: {row['Recall']:.4f}\")\n",
    "        print(f\"   ğŸ“ˆ Coverage: {row['Coverage_%']:.2f}%\")\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ Evaluation failed - no results generated\")\n",
    "\n",
    "print(\"\\\\n\" + \"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
