{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfd9df5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b555751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "🧪 TESTING: BUDGET-APPROPRIATE PRODUCTS\n",
      "================================================================================\n",
      "🔍 Let's find these products and see their multipliers:\n",
      "\n",
      "📦 Confidence in a Cream Anti-Aging Hydrating Moistur...\n",
      "   💰 Price: $20.0\n",
      "   🎭 Expected match: 98%\n",
      "   📊 Base rating: 4.98\n",
      "   🎭 Skin multiplier: 0.990\n",
      "   ⚡ Final rating: 4.93\n",
      "   🎯 Calculated match: 98%\n",
      "   💰 Within budget: ✅\n",
      "\n",
      "💡 SUMMARY:\n",
      "The match percentages are lower now because:\n",
      "✅ We apply realistic skin profile scoring\n",
      "✅ Products get multipliers based on skin type/concern matches\n",
      "✅ This prevents all products from showing 100% match\n",
      "✅ It's actually MORE ACCURATE than showing everything as 100%!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d0fa48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "🔬 ANALYZING: SKIN PROFILE MULTIPLIER COMPONENTS\n",
      "================================================================================\n",
      "👤 USER PROFILE:\n",
      "   Skin type: dry\n",
      "   Concerns: []\n",
      "   Budget: Under $25\n",
      "\n",
      "📦 PRODUCT DETAILS:\n",
      "   Price: $68.0\n",
      "   Category: Eye Creams & Treatments\n",
      "\n",
      "💰 BUDGET ANALYSIS:\n",
      "   User budget: Under $25\n",
      "   Budget range: $0 - $25\n",
      "   Product price: $68.0\n",
      "   Within budget: ❌ NO\n",
      "\n",
      "🧮 MULTIPLIER CALCULATION:\n",
      "   Starting multiplier: 1.0\n",
      "   After budget mismatch (×0.7): 0.7\n",
      "   Final multiplier (capped): 0.7\n",
      "\n",
      "💡 ISSUE IDENTIFIED:\n",
      "   The product costs $68.0 but your budget is 'Under $25'\n",
      "   This triggers a 0.7× penalty, making the match percentage lower\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17c48f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "🔍 DEBUGGING: MATCH PERCENTAGE CALCULATION\n",
      "================================================================================\n",
      "\n",
      "🧪 Testing product: P467602\n",
      "📦 Product: Triple Algae Eye Renewal Balm Eye Cream\n",
      "💰 Price: $68.0\n",
      "🏷️ Category: Eye Creams & Treatments\n",
      "\n",
      "🎭 Skin profile multiplier: 0.630\n",
      "📊 Base rating (from popularity): 3.899\n",
      "⚡ Adjusted rating (after skin filter): 2.456\n",
      "🎯 Match percentage: 49%\n",
      "\n",
      "💡 EXPLANATION:\n",
      "   - Base rating: 3.9/5 → would be 77% match\n",
      "   - Skin multiplier: 0.630 (based on skin type/budget/concerns)\n",
      "   - Final rating: 2.5/5 → 49% match\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f84d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "🏆 FINAL TEST: COMPLETE SOLUTION\n",
      "================================================================================\n",
      "\n",
      "==================== TEST 1: Under $25 ====================\n",
      "\n",
      "🎯 NEW USER DETECTED: 88889\n",
      "Using Content-Based Filtering (new user, fallback to same-category recommendations)\n",
      "🏷️ Selected product category: Moisturizers\n",
      "💰 Budget filter: $0 - $25\n",
      "📦 Found 385 products in same category\n",
      "🔍 After budget filtering: 34 products match budget\n",
      "\n",
      "🎯 TOP 3 SKIN-AWARE SAME-CATEGORY RECOMMENDATIONS:\n",
      "  1. Confidence in a Cream Anti-Aging Hydrating Moisturizer\n",
      "     Category: Moisturizers | Price: $20.0\n",
      "     Rating: 4.93 | Match: 98%\n",
      "\n",
      "  2. Mini Barrier+ Triple Lipid-Peptide Face Cream\n",
      "     Category: Moisturizers | Price: $20.0\n",
      "     Rating: 4.85 | Match: 97%\n",
      "\n",
      "  3. Mini Indigo Overnight Repair Serum in Cream Treatment\n",
      "     Category: Moisturizers | Price: $22.0\n",
      "     Rating: 3.83 | Match: 76%\n",
      "\n",
      "\n",
      "✅ Budget constraint: Under $25 (max $25)\n",
      "📊 Actual max price in recommendations: $22.0\n",
      "✅ Budget constraint RESPECTED\n",
      "------------------------------------------------------------\n",
      "\n",
      "==================== TEST 2: $25-$50 ====================\n",
      "\n",
      "🎯 NEW USER DETECTED: 88890\n",
      "Using Content-Based Filtering (new user, fallback to same-category recommendations)\n",
      "🏷️ Selected product category: Moisturizers\n",
      "💰 Budget filter: $25 - $50\n",
      "📦 Found 385 products in same category\n",
      "🔍 After budget filtering: 128 products match budget\n",
      "\n",
      "🎯 TOP 3 SKIN-AWARE SAME-CATEGORY RECOMMENDATIONS:\n",
      "  1. The True Cream Aqua Bomb\n",
      "     Category: Moisturizers | Price: $38.0\n",
      "     Rating: 4.95 | Match: 99%\n",
      "\n",
      "  2. The True Cream Moisturizing Bomb\n",
      "     Category: Moisturizers | Price: $38.0\n",
      "     Rating: 4.95 | Match: 99%\n",
      "\n",
      "  3. Dramatically Different Moisturizing Gel\n",
      "     Category: Moisturizers | Price: $32.5\n",
      "     Rating: 4.95 | Match: 99%\n",
      "\n",
      "\n",
      "✅ Budget constraint: $25-$50 (max $50)\n",
      "📊 Actual max price in recommendations: $38.0\n",
      "✅ Budget constraint RESPECTED\n",
      "------------------------------------------------------------\n",
      "\n",
      "==================== TEST 3: $50-$100 ====================\n",
      "\n",
      "🎯 NEW USER DETECTED: 88891\n",
      "Using Content-Based Filtering (new user, fallback to same-category recommendations)\n",
      "🏷️ Selected product category: Moisturizers\n",
      "💰 Budget filter: $50 - $100\n",
      "📦 Found 385 products in same category\n",
      "🔍 After budget filtering: 165 products match budget\n",
      "\n",
      "🎯 TOP 3 SKIN-AWARE SAME-CATEGORY RECOMMENDATIONS:\n",
      "  1. Vitamin Enriched Face Base Priming Moisturizer\n",
      "     Category: Moisturizers | Price: $66.0\n",
      "     Rating: 4.95 | Match: 99%\n",
      "\n",
      "  2. Magic Cream Moisturizer with Hyaluronic Acid\n",
      "     Category: Moisturizers | Price: $100.0\n",
      "     Rating: 4.95 | Match: 99%\n",
      "\n",
      "  3. Protini Polypeptide Firming Refillable Moisturizer\n",
      "     Category: Moisturizers | Price: $68.0\n",
      "     Rating: 4.95 | Match: 99%\n",
      "\n",
      "\n",
      "✅ Budget constraint: $50-$100 (max $100)\n",
      "📊 Actual max price in recommendations: $100.0\n",
      "✅ Budget constraint RESPECTED\n",
      "------------------------------------------------------------\n",
      "\n",
      "🎉 SOLUTION SUMMARY:\n",
      "✅ Same-category filtering: Products from selected product's category\n",
      "✅ Budget filtering: Respects user's budget constraints\n",
      "✅ Skin profile boost: Enhances ratings based on skin type/concerns\n",
      "✅ Streamlit integration: Updated app.py to use new method\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2bd09d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "🧪 TESTING: SAME-CATEGORY + SKIN PROFILE FILTERING\n",
      "================================================================================\n",
      "\n",
      "🧪 Testing with user: 99999\n",
      "🎯 Selected product: P439055\n",
      "💰 Budget constraint: Under $25\n",
      "🧴 Skin type: Dry\n",
      "🎭 Concerns: dehydration, aging\n",
      "\n",
      "🎯 NEW USER DETECTED: 99999\n",
      "Using Content-Based Filtering (new user, fallback to same-category recommendations)\n",
      "🏷️ Selected product category: Moisturizers\n",
      "💰 Budget filter: $0 - $25\n",
      "📦 Found 385 products in same category\n",
      "🔍 After budget filtering: 34 products match budget\n",
      "\n",
      "🎯 TOP 5 SKIN-AWARE SAME-CATEGORY RECOMMENDATIONS:\n",
      "  1. Confidence in a Cream Anti-Aging Hydrating Moisturizer\n",
      "     Category: Moisturizers | Price: $20.0\n",
      "     Rating: 4.93 | Match: 98%\n",
      "\n",
      "  2. Mini Barrier+ Triple Lipid-Peptide Face Cream\n",
      "     Category: Moisturizers | Price: $20.0\n",
      "     Rating: 4.85 | Match: 97%\n",
      "\n",
      "  3. Mini Indigo Overnight Repair Serum in Cream Treatment\n",
      "     Category: Moisturizers | Price: $22.0\n",
      "     Rating: 3.83 | Match: 76%\n",
      "\n",
      "  4. C.E.O. Vitamin C Brightening Rich Hydration Moisturizer\n",
      "     Category: Moisturizers | Price: $22.0\n",
      "     Rating: 3.69 | Match: 73%\n",
      "\n",
      "  5. Peptide Moisturizer\n",
      "     Category: Moisturizers | Price: $15.99\n",
      "     Rating: 3.59 | Match: 71%\n",
      "\n",
      "\n",
      "✅ Generated 5 skin-aware same-category recommendations!\n",
      "================================================================================\n",
      "\n",
      "🧪 Testing with user: 99999\n",
      "🎯 Selected product: P439055\n",
      "💰 Budget constraint: Under $25\n",
      "🧴 Skin type: Dry\n",
      "🎭 Concerns: dehydration, aging\n",
      "\n",
      "🎯 NEW USER DETECTED: 99999\n",
      "Using Content-Based Filtering (new user, fallback to same-category recommendations)\n",
      "🏷️ Selected product category: Moisturizers\n",
      "💰 Budget filter: $0 - $25\n",
      "📦 Found 385 products in same category\n",
      "🔍 After budget filtering: 34 products match budget\n",
      "\n",
      "🎯 TOP 5 SKIN-AWARE SAME-CATEGORY RECOMMENDATIONS:\n",
      "  1. Confidence in a Cream Anti-Aging Hydrating Moisturizer\n",
      "     Category: Moisturizers | Price: $20.0\n",
      "     Rating: 4.93 | Match: 98%\n",
      "\n",
      "  2. Mini Barrier+ Triple Lipid-Peptide Face Cream\n",
      "     Category: Moisturizers | Price: $20.0\n",
      "     Rating: 4.85 | Match: 97%\n",
      "\n",
      "  3. Mini Indigo Overnight Repair Serum in Cream Treatment\n",
      "     Category: Moisturizers | Price: $22.0\n",
      "     Rating: 3.83 | Match: 76%\n",
      "\n",
      "  4. C.E.O. Vitamin C Brightening Rich Hydration Moisturizer\n",
      "     Category: Moisturizers | Price: $22.0\n",
      "     Rating: 3.69 | Match: 73%\n",
      "\n",
      "  5. Peptide Moisturizer\n",
      "     Category: Moisturizers | Price: $15.99\n",
      "     Rating: 3.59 | Match: 71%\n",
      "\n",
      "\n",
      "✅ Generated 5 skin-aware same-category recommendations!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# TESTING: Same-Category Recommendations WITH Skin Profile Filtering\n",
    "print(\"=\"*80)\n",
    "print(\"🧪 TESTING: SAME-CATEGORY + SKIN PROFILE FILTERING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Reload the updated recommender\n",
    "import importlib\n",
    "import sys\n",
    "if 'utils.recommender' in sys.modules:\n",
    "    importlib.reload(sys.modules['utils.recommender'])\n",
    "from utils.recommender import EnhancedHybridRecommender\n",
    "\n",
    "# Reinitialize with the updated class\n",
    "recommender = EnhancedHybridRecommender(\n",
    "    train_path=\"data/CleanedDataSet/train_skincare.csv\",\n",
    "    products_path=\"data/CleanedDataSet/filtered_skincare_products.csv\",\n",
    "    content_model_path=\"models/product_embeddings.pkl\",\n",
    "    svd_model_path=\"models/surprise_svd_model.pkl\"\n",
    ")\n",
    "\n",
    "# Test user with budget constraint\n",
    "test_user_id = 99999\n",
    "selected_product_id = \"P439055\"  # GENIUS Sleeping Collagen Moisturizer ($98)\n",
    "\n",
    "# Add skin profile with budget constraint\n",
    "recommender.add_skin_profile(test_user_id, {\n",
    "    'skin_type': 'Dry',\n",
    "    'concerns': ['dehydration', 'aging'],\n",
    "    'budget': 'Under $25',  # This should filter out expensive products\n",
    "    'num_products': 5\n",
    "})\n",
    "\n",
    "print(f\"\\n🧪 Testing with user: {test_user_id}\")\n",
    "print(f\"🎯 Selected product: {selected_product_id}\")\n",
    "print(\"💰 Budget constraint: Under $25\")\n",
    "print(\"🧴 Skin type: Dry\")\n",
    "print(\"🎭 Concerns: dehydration, aging\")\n",
    "\n",
    "# Test the enhanced demo recommendations with skin profile filtering\n",
    "recommendations = recommender.enhanced_demo_recommendations(\n",
    "    user_id=test_user_id,\n",
    "    top_n=5,\n",
    "    content_weight=0.4,\n",
    "    collab_weight=0.6,\n",
    "    selected_product_id=selected_product_id\n",
    ")\n",
    "\n",
    "print(f\"\\n✅ Generated {len(recommendations)} skin-aware same-category recommendations!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "15273567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "🔬 COMPARISON: OLD vs NEW RECOMMENDATION APPROACHES\n",
      "================================================================================\n",
      "🧪 Testing with new user: 8888888\n",
      "🎯 Selected product: P421277\n",
      "📦 Product: GENIUS Liquid Collagen Serum\n",
      "🏷️ Category: Face Serums\n",
      "\n",
      "==================================================\n",
      "🔴 OLD APPROACH: Content-based predict\n",
      "==================================================\n",
      "Old approach result - Score: 3.347, Confidence: 1.000\n",
      "❌ This just gives category average ratings, not same-category filtering\n",
      "\n",
      "==================================================\n",
      "🟢 NEW APPROACH: Enhanced demo with same-category filtering\n",
      "==================================================\n",
      "\n",
      "🎯 NEW USER DETECTED: 8888888\n",
      "Using Content-Based Filtering (new user, fallback to same-category recommendations)\n",
      "🏷️ Selected product category: Face Serums\n",
      "📦 Found 378 products in same category\n",
      "\n",
      "🎯 TOP 3 SAME-CATEGORY RECOMMENDATIONS:\n",
      "  1. Skinlongevity Long Life Herb Anti-Aging Face Serum\n",
      "     Category: Face Serums\n",
      "     Rating: 5.00 | Match: 100%\n",
      "\n",
      "  2. Vinoperfect Radiance Dark Spot Serum Vitamin C Alternative\n",
      "     Category: Face Serums\n",
      "     Rating: 5.00 | Match: 100%\n",
      "\n",
      "  3. T.L.C. Framboos Glycolic Resurfacing Night Serum\n",
      "     Category: Face Serums\n",
      "     Rating: 5.00 | Match: 100%\n",
      "\n",
      "✅ New approach generated 3 same-category recommendations!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# COMPARISON: Old vs New Recommendation Approaches for New Users\n",
    "print(\"=\"*80)\n",
    "print(\"🔬 COMPARISON: OLD vs NEW RECOMMENDATION APPROACHES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "new_user_id = 8888888  # New user ID\n",
    "selected_product_id = \"P421277\"  # Another valid product\n",
    "\n",
    "print(f\"🧪 Testing with new user: {new_user_id}\")\n",
    "print(f\"🎯 Selected product: {selected_product_id}\")\n",
    "\n",
    "# Get product info\n",
    "product_info = recommender.prod_df[recommender.prod_df['product_id'].astype(str) == selected_product_id].iloc[0]\n",
    "print(f\"📦 Product: {product_info['product_name']}\")\n",
    "print(f\"🏷️ Category: {product_info['tertiary_category']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"🔴 OLD APPROACH: Content-based predict\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Test old approach (_content_based_predict)\n",
    "old_score, old_conf = recommender._content_based_predict(new_user_id, selected_product_id)\n",
    "print(f\"Old approach result - Score: {old_score:.3f}, Confidence: {old_conf:.3f}\")\n",
    "print(\"❌ This just gives category average ratings, not same-category filtering\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"🟢 NEW APPROACH: Enhanced demo with same-category filtering\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Test new approach\n",
    "new_recommendations = recommender.enhanced_demo_recommendations(\n",
    "    user_id=new_user_id,\n",
    "    top_n=3,\n",
    "    selected_product_id=selected_product_id\n",
    ")\n",
    "\n",
    "print(f\"✅ New approach generated {len(new_recommendations)} same-category recommendations!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "16c029a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "🧪 TESTING SAME-CATEGORY RECOMMENDATIONS - ROUND 2\n",
      "================================================================================\n",
      "Testing with new user: 9999999\n",
      "Selected product ID: P439055\n",
      "\n",
      "🎯 NEW USER DETECTED: 9999999\n",
      "Using Content-Based Filtering (new user, fallback to same-category recommendations)\n",
      "🏷️ Selected product category: Moisturizers\n",
      "📦 Found 385 products in same category\n",
      "\n",
      "🎯 TOP 5 SAME-CATEGORY RECOMMENDATIONS:\n",
      "  1. The True Cream Aqua Bomb\n",
      "     Category: Moisturizers\n",
      "     Rating: 5.00 | Match: 100%\n",
      "\n",
      "  2. The True Cream Moisturizing Bomb\n",
      "     Category: Moisturizers\n",
      "     Rating: 5.00 | Match: 100%\n",
      "\n",
      "  3. Vitamin Enriched Face Base Priming Moisturizer\n",
      "     Category: Moisturizers\n",
      "     Rating: 5.00 | Match: 100%\n",
      "\n",
      "  4. Magic Cream Moisturizer with Hyaluronic Acid\n",
      "     Category: Moisturizers\n",
      "     Rating: 5.00 | Match: 100%\n",
      "\n",
      "  5. Dramatically Different Moisturizing Gel\n",
      "     Category: Moisturizers\n",
      "     Rating: 5.00 | Match: 100%\n",
      "\n",
      "\n",
      "✅ Generated 5 recommendations\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Test same-category recommendations with a valid product ID\n",
    "print(\"=\"*80)\n",
    "print(\"🧪 TESTING SAME-CATEGORY RECOMMENDATIONS - ROUND 2\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Test with a new user and a valid product ID\n",
    "new_user_id = 9999999  # This should be a new user\n",
    "selected_product_id = \"P439055\"  # Valid product from the dataset\n",
    "\n",
    "print(f\"Testing with new user: {new_user_id}\")\n",
    "print(f\"Selected product ID: {selected_product_id}\")\n",
    "\n",
    "# Test the enhanced demo recommendations with same-category filtering\n",
    "recommendations = recommender.enhanced_demo_recommendations(\n",
    "    user_id=new_user_id,\n",
    "    top_n=5,\n",
    "    content_weight=best_content_weight,\n",
    "    collab_weight=best_collab_weight,\n",
    "    selected_product_id=selected_product_id\n",
    ")\n",
    "\n",
    "print(f\"\\n✅ Generated {len(recommendations)} recommendations\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac12593c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 INITIALIZING ENHANCED HYBRID RECOMMENDER\n",
      "================================================================================\n",
      "📦 Loading pre-trained models...\n",
      "✅ Content model loaded: 1760 products\n",
      "✅ SVD model loaded\n",
      "📈 Global average rating from SVD: 3.934\n",
      "✅ Index mappings created\n",
      "⚡ Precomputing product features for faster similarity...\n",
      "✅ Precomputed features for 1760 products\n",
      "📊 Preloading data...\n",
      "✅ Test data loaded: 160291 records\n",
      "✅ Train data loaded: 641164 records\n",
      "🔨 Building user history cache...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caching user histories: 100%|██████████| 430159/430159 [00:56<00:00, 7637.30it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Calculating product popularity...\n",
      "=== Dataset Overview ===\n",
      "Train set: 641,164 rows | 357,909 users | 1,760 products\n",
      "Test set: 160,291 rows | 131,518 users | 1,705 products\n",
      "Products catalog: 1,760 items\n",
      "========================\n",
      "✅ Enhanced Hybrid Recommender initialized successfully!\n",
      "\n",
      "✅ ENHANCED INITIALIZATION COMPLETE!\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting ratings: 100%|██████████| 1752/1752 [00:02<00:00, 670.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎯 ENHANCED RECOMMENDATIONS FOR USER 2128891661:\n",
      "   Weights: Content=0.2, SVD=0.8\n",
      "================================================================================\n",
      "1. Vitamin Enriched Face Base Jumbo (Bobbi Brown)\n",
      "   📍 Moisturizers • 💰 $99.00\n",
      "   ⭐ 4.3350/5 • 🔍 86% match\n",
      "   🆔 P468634\n",
      "   💎 Excellent match! Based on your preferences and highly rated by similar users\n",
      "\n",
      "2. Ultra Repair Firming Collagen Cream with Peptides and Niacinamide (First Aid Beauty)\n",
      "   📍 Moisturizers • 💰 $44.00\n",
      "   ⭐ 4.2842/5 • 🔍 85% match\n",
      "   🆔 P468821\n",
      "   💎 Excellent match! Based on your preferences and highly rated by similar users\n",
      "\n",
      "3. Resveratrol Lift Retinol Alternative Firming Cashmere Moisturizer (Caudalie)\n",
      "   📍 Moisturizers • 💰 $69.00\n",
      "   ⭐ 4.2702/5 • 🔍 85% match\n",
      "   🆔 P467750\n",
      "   💎 Excellent match! Based on your preferences and highly rated by similar users\n",
      "\n",
      "4. Absolue Rich Cream Moisturizer (Lancôme)\n",
      "   📍 Moisturizers • 💰 $270.00\n",
      "   ⭐ 4.2571/5 • 🔍 85% match\n",
      "   🆔 P482025\n",
      "   💎 Excellent match! Based on your preferences and highly rated by similar users\n",
      "\n",
      "5. Hydra Vizor Invisible Moisturizer Broad Spectrum SPF 30 Sunscreen with Niacinamide Refill (Fenty Skin)\n",
      "   📍 Moisturizers • 💰 $35.00\n",
      "   ⭐ 4.2531/5 • 🔍 85% match\n",
      "   🆔 P476485\n",
      "   💎 Excellent match! Based on your preferences and highly rated by similar users\n",
      "\n",
      "\n",
      "📊 Evaluating recommender system...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 160291/160291 [04:43<00:00, 566.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📈 Evaluation Results:\n",
      "RMSE: 0.9711\n",
      "MAE: 0.7986\n",
      "Accuracy: 0.8682\n",
      "Precision: 0.8679\n",
      "Recall: 0.9914\n",
      "F1: 0.9255\n",
      "Coverage: 0.9631\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from math import sqrt\n",
    "from tqdm import tqdm\n",
    "import joblib\n",
    "from typing import Dict, List, Tuple\n",
    "from surprise import dump\n",
    "import warnings\n",
    "import re\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class EnhancedHybridRecommender:\n",
    "    def __init__(self, train_path: str, test_path: str, products_path: str,\n",
    "                 content_model_path: str, svd_model_path: str):\n",
    "        \"\"\"\n",
    "        Hybrid Recommender: SVD + Content-based filtering with improvements\n",
    "        \"\"\"\n",
    "        self.train_path = train_path\n",
    "        self.test_path = test_path\n",
    "        self.products_path = products_path\n",
    "        self.content_model_path = content_model_path\n",
    "        self.svd_model_path = svd_model_path\n",
    "\n",
    "        # Initialize attributes\n",
    "        self.prod_df = None\n",
    "        self.prod_embeds = None\n",
    "        self.svd_model = None\n",
    "        self.global_avg = 3.0\n",
    "        self.test_df = None\n",
    "        self.train_df = None\n",
    "        self.user_history_cache = {}\n",
    "        self.product_popularity = {}\n",
    "        self.product_features = {}\n",
    "        self.skin_profiles = {}\n",
    "        \n",
    "        # Load models and data\n",
    "        self._load_models()\n",
    "        self._preload_data()\n",
    "        \n",
    "        # ------------------------------\n",
    "        # Skin type + concern rules \n",
    "        # ------------------------------\n",
    "        # Regex patterns to detect skin types from text\n",
    "        self.SKIN_TYPE_PATTERNS = [\n",
    "            (r\"\\b(?:good|best)\\s*for:\\s*oily\\b\", \"oily\"),\n",
    "            (r\"\\b(?:good|best)\\s*for:\\s*dry\\b\", \"dry\"),\n",
    "            (r\"\\b(?:good|best)\\s*for:\\s*combination\\b\", \"combination\"),\n",
    "            (r\"\\b(?:good|best)\\s*for:\\s*sensitive\\b\", \"sensitive\"),\n",
    "            (r\"\\b(?:good|best)\\s*for:\\s*normal\\b\", \"normal\"),\n",
    "            (r\"\\b(oily skin|oily)\\b\", \"oily\"),\n",
    "            (r\"\\b(dry skin|dry)\\b\", \"dry\"),\n",
    "            (r\"\\b(combination skin|combination|combo)\\b\", \"combination\"),\n",
    "            (r\"\\b(sensitive skin|sensitive)\\b\", \"sensitive\"),\n",
    "            (r\"\\b(normal skin|normal)\\b\", \"normal\"),\n",
    "            (r\"\\bfor\\s+sensitive\\s+skin\\b\", \"sensitive\"),\n",
    "            (r\"\\bsuitable\\s+for\\s+sensitive\\b\", \"sensitive\"),\n",
    "            (r\"\\bfor\\s+sensitive\\b\", \"sensitive\"),\n",
    "            (r\"\\bhypoallergenic\\b\", \"sensitive\"),\n",
    "            (r\"\\bgentle\\b\", \"sensitive\"),\n",
    "        ]\n",
    "        # Regex patterns to detect skin concerns from claims or product name\n",
    "        self.SKIN_CONCERN_PATTERNS = [\n",
    "            (r\"\\b(acne|blemish|breakout|pimple)\\b\", \"acne\"),\n",
    "            (r\"\\bpores?\\b\", \"pores\"),\n",
    "            (r\"\\b(dark spot|hyperpigment|discoloration|melasma)\\b\", \"hyperpigmentation\"),\n",
    "            (r\"\\b(wrinkle|fine line|anti[- ]?aging|firming|loss of firmness|elasticity)\\b\", \"aging\"),\n",
    "            (r\"\\b(redness|rosacea|irritation|calming|soothing)\\b\", \"redness\"),\n",
    "            (r\"\\b(dryness|dehydration|hydrating|moisturizing|moisturising|barrier)\\b\", \"dehydration\"),\n",
    "            (r\"\\b(dull(ness)?|brighten(ing)?|glow|radiance)\\b\", \"dullness\"),\n",
    "            (r\"\\boil(y| control|iness)\\b\", \"oil-control\"),\n",
    "            (r\"\\b(blackhead|whitehead|congestion)\\b\", \"blackheads\"),\n",
    "            (r\"\\b(uneven (tone|texture)|texture|resurfacing)\\b\", \"texture\"),\n",
    "            (r\"\\b(dark circle|dark circles)\\b\", \"dark-circles\"),\n",
    "        ]\n",
    "\n",
    "        # Ingredient-based concern mapping\n",
    "        self.INGREDIENT_CONCERN_PATTERNS = [\n",
    "            (r\"\\b(salicylic acid|beta hydroxy|bha|willow bark|benzoyl peroxide|sulfur|zinc pca|zinc)\\b\", {\"acne\",\"pores\",\"oil-control\"}),\n",
    "            (r\"\\b(kaolin|bentonite|clay|charcoal)\\b\", {\"pores\",\"oil-control\"}),\n",
    "            (r\"\\b(tea tree|melaleuca)\\b\", {\"acne\"}),\n",
    "            (r\"\\b(hyaluronic acid|sodium hyaluronate|glycerin|panthenol|urea|betaine|trehalose|aloe)\\b\", {\"dehydration\"}),\n",
    "            (r\"\\b(ceramide|ceramides|cholesterol|squalane|squalene|shea|shea butter)\\b\", {\"dehydration\"}),\n",
    "            (r\"\\b(retinol|retinal|retinoate|bakuchiol|peptide|matrixyl|collagen|coenzyme ?q10|ubiquinone)\\b\", {\"aging\"}),\n",
    "            (r\"\\b(vitamin ?c|ascorbic|ascorbyl|ethyl ascorbic|magnesium ascorbyl|sodium ascorbyl|alpha arbutin|tranexamic|azelaic|kojic|licorice|glycyrrhiza)\\b\", {\"hyperpigmentation\",\"dullness\"}),\n",
    "            (r\"\\b(centella|cica|madecassoside|asiaticoside|allantoin|bisabolol|beta glucan|green tea|oat|colloidal oatmeal)\\b\", {\"redness\"}),\n",
    "            (r\"\\b(aha|glycolic|lactic|mandelic|tartaric|citric|pha|gluconolactone|lactobionic)\\b\", {\"texture\",\"dullness\"}),\n",
    "        ]\n",
    "        print(\"✅ Enhanced Hybrid Recommender initialized successfully!\")\n",
    "\n",
    "    def _load_models(self) -> None:\n",
    "        \"\"\"Load pre-trained models\"\"\"\n",
    "        print(\"📦 Loading pre-trained models...\")\n",
    "        \n",
    "        # Load content-based model\n",
    "        if os.path.exists(self.content_model_path):\n",
    "            self.prod_df, self.prod_embeds = joblib.load(self.content_model_path)\n",
    "            print(f\"✅ Content model loaded: {len(self.prod_df)} products\")\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"Content model not found at {self.content_model_path}\")\n",
    "        \n",
    "        # Load SVD model\n",
    "        if os.path.exists(self.svd_model_path):\n",
    "            _, self.svd_model = dump.load(self.svd_model_path)\n",
    "            print(\"✅ SVD model loaded\")\n",
    "            \n",
    "            # Get global average from SVD\n",
    "            if hasattr(self.svd_model, 'trainset') and self.svd_model.trainset:\n",
    "                self.global_avg = self.svd_model.trainset.global_mean\n",
    "                print(f\"📈 Global average rating from SVD: {self.global_avg:.3f}\")\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"SVD model not found at {self.svd_model_path}\")\n",
    "        \n",
    "        # Create index mappings\n",
    "        self.product_id_to_idx = {str(pid): idx for idx, pid in enumerate(self.prod_df[\"product_id\"])}\n",
    "        print(\"✅ Index mappings created\")\n",
    "        \n",
    "        # Precompute product features for faster similarity calculation\n",
    "        self.precompute_product_features()\n",
    "\n",
    "    def precompute_product_features(self):\n",
    "        \"\"\"Precompute product features for faster similarity calculation\"\"\"\n",
    "        print(\"⚡ Precomputing product features for faster similarity...\")\n",
    "        \n",
    "        self.product_features = {}\n",
    "        for _, row in self.prod_df.iterrows():\n",
    "            product_id = str(row[\"product_id\"])\n",
    "            self.product_features[product_id] = {\n",
    "                'brand': row[\"brand_name\"],\n",
    "                'category': row[\"tertiary_category\"],\n",
    "                'price': row[\"price_usd\"] if pd.notna(row[\"price_usd\"]) else 0,\n",
    "                'embedding': self.prod_embeds[self.product_id_to_idx[product_id]]\n",
    "            }\n",
    "        \n",
    "        print(f\"✅ Precomputed features for {len(self.product_features)} products\")\n",
    "\n",
    "    def _preload_data(self):\n",
    "        print(\"📊 Preloading data...\")\n",
    "\n",
    "        # Load a small sample just to detect available columns\n",
    "        test_sample = pd.read_csv(self.test_path, nrows=5)\n",
    "\n",
    "        # Base columns we always need\n",
    "        usecols = [\"author_id\", \"product_id\", \"rating\"]\n",
    "\n",
    "        # ✅ Try to detect a timestamp column from the sample\n",
    "        time_col = None\n",
    "        for col in [\"timestamp\", \"submission_time\", \"review_date\"]:\n",
    "            if col in test_sample.columns:\n",
    "                time_col = col\n",
    "                usecols.append(col)\n",
    "                break\n",
    "\n",
    "        # Load full test/train datasets with only needed columns\n",
    "        self.test_df = pd.read_csv(self.test_path, usecols=usecols)\n",
    "        self.train_df = pd.read_csv(self.train_path, usecols=[\"author_id\", \"product_id\", \"rating\"])\n",
    "\n",
    "        # Build user history cache (from train)\n",
    "        self.user_histories = (\n",
    "            self.train_df.groupby(\"author_id\")[\"product_id\"].apply(list).to_dict()\n",
    "        )\n",
    "\n",
    "        print(f\"✅ Test data loaded: {len(self.test_df)} records\")\n",
    "        print(f\"✅ Train data loaded: {len(self.train_df)} records\")\n",
    "\n",
    "        \n",
    "        # Build user history cache - OPTIMIZED\n",
    "        print(\"🔨 Building user history cache...\")\n",
    "        all_ratings = pd.concat([self.train_df, self.test_df])\n",
    "        \n",
    "        # Use groupby for faster processing\n",
    "        user_groups = all_ratings.groupby(\"author_id\")\n",
    "        for user_id, group in tqdm(user_groups, desc=\"Caching user histories\"):\n",
    "            self.user_history_cache[str(user_id)] = {\n",
    "                'rated_products': group[\"product_id\"].astype(str).tolist(),\n",
    "                'ratings': group[\"rating\"].tolist(),\n",
    "                'avg_rating': group[\"rating\"].mean()\n",
    "            }\n",
    "        \n",
    "        # Calculate product popularity\n",
    "        print(\"📊 Calculating product popularity...\")\n",
    "        # FIXED: Changed ast(str) to astype(str)\n",
    "        self.product_popularity = all_ratings['product_id'].astype(str).value_counts().to_dict()\n",
    "        \n",
    "        print(\"=== Dataset Overview ===\")\n",
    "        print(f\"Train set: {len(self.train_df):,} rows | {self.train_df['author_id'].nunique():,} users | {self.train_df['product_id'].nunique():,} products\")\n",
    "        print(f\"Test set: {len(self.test_df):,} rows | {self.test_df['author_id'].nunique():,} users | {self.test_df['product_id'].nunique():,} products\")\n",
    "        print(f\"Products catalog: {len(self.prod_df):,} items\")\n",
    "        print(\"========================\")\n",
    "\n",
    "    def add_skin_profile(self, user_id: str, skin_data: Dict):\n",
    "        \"\"\"添加用户皮肤分析数据\"\"\"\n",
    "        user_id = str(user_id)\n",
    "        self.skin_profiles[user_id] = skin_data\n",
    "        print(f\"✅ Added skin profile for user {user_id}\")\n",
    "        print(f\"   Skin type: {skin_data.get('skin_type', 'N/A')}\")\n",
    "        print(f\"   Concerns: {skin_data.get('concerns', 'N/A')}\")\n",
    "        print(f\"   Budget: {skin_data.get('budget', 'N/A')}\")\n",
    "\n",
    "\n",
    "    def _extract_skin_tags(self, text: str):\n",
    "        \"\"\"\n",
    "        Extract possible skin types and skin concerns from text.\n",
    "        Returns two lists: (matched_types, matched_concerns).\n",
    "        \"\"\"\n",
    "        text = text.lower()\n",
    "\n",
    "        # Define possible tags (expand if needed)\n",
    "        skin_types = [\"oily\", \"dry\", \"combination\", \"normal\", \"sensitive\"]\n",
    "        skin_concerns = [\n",
    "            \"acne\", \"wrinkles\", \"fine lines\", \"dark spots\", \n",
    "            \"pigmentation\", \"redness\", \"pores\", \"dullness\", \n",
    "            \"eczema\", \"rosacea\", \"hydration\", \"blackheads\"\n",
    "        ]\n",
    "\n",
    "        matched_types = [t for t in skin_types if t in text]\n",
    "        matched_concerns = [c for c in skin_concerns if c in text]\n",
    "\n",
    "        return matched_types, matched_concerns\n",
    "\n",
    "\n",
    "    def _budget_range(self, budget_str: str):\n",
    "        \"\"\"Convert budget category string into (min_price, max_price).\"\"\"\n",
    "        if not budget_str:\n",
    "            return 0, float(\"inf\")\n",
    "\n",
    "        budget_str = budget_str.strip().lower()\n",
    "        if \"no budget\" in budget_str:       # ✅ handles \"No budget limit\"\n",
    "            return 0, float(\"inf\")\n",
    "        elif \"under\" in budget_str:\n",
    "            return 0, 25\n",
    "        elif \"$25\" in budget_str and \"$50\" in budget_str:\n",
    "            return 25, 50\n",
    "        elif \"$50\" in budget_str and \"$100\" in budget_str:\n",
    "            return 50, 100\n",
    "        elif \"over\" in budget_str or \"above\" in budget_str:\n",
    "            return 100, float(\"inf\")\n",
    "        return 0, float(\"inf\")  # fallback\n",
    "\n",
    "\n",
    "\n",
    "    def filter_by_skin_profile(self, product_id: int, user_id: int):\n",
    "        \"\"\"\n",
    "        Soft filtering: adjust score multiplier based on match\n",
    "        between product tags and user's skin profile.\n",
    "        \"\"\"\n",
    "        user_id = str(user_id)\n",
    "        if user_id not in self.skin_profiles:\n",
    "            return 1.0  # no profile → neutral\n",
    "\n",
    "        user_profile = self.skin_profiles[user_id]\n",
    "        user_type = user_profile.get(\"skin_type\", \"\").lower()\n",
    "        \n",
    "        # ✅ Handle both string and list for concerns\n",
    "        concerns = user_profile.get(\"concerns\", [])\n",
    "        if isinstance(concerns, str):\n",
    "            user_concerns = [concerns.lower()]\n",
    "        else:\n",
    "            user_concerns = [c.lower() for c in concerns]\n",
    "\n",
    "        user_budget = user_profile.get(\"budget\", \"\")\n",
    "\n",
    "        # Get product details\n",
    "        product = self.prod_df[self.prod_df[\"product_id\"].astype(str) == str(product_id)].iloc[0]\n",
    "        product_text = \" \".join([\n",
    "            str(product.get(\"product_name\", \"\")),\n",
    "            str(product.get(\"combined_features\", \"\")),\n",
    "            str(product.get(\"ingredients\", \"\")),\n",
    "            str(product.get(\"claims\", \"\")),\n",
    "        ])\n",
    "        product_price = product.get(\"price_usd\", 0)\n",
    "\n",
    "        # Extract tags from product text\n",
    "        matched_types, matched_concerns = self._extract_skin_tags(product_text)\n",
    "\n",
    "        # Start with neutral multiplier\n",
    "        multiplier = 1.0\n",
    "\n",
    "        # Skin type match\n",
    "        if user_type in matched_types:\n",
    "            multiplier *= 1.2\n",
    "        elif user_type:  # mismatch but user specified\n",
    "            multiplier *= 0.9\n",
    "\n",
    "        # Skin concern match (✅ supports multiple concerns)\n",
    "        if any(c in matched_concerns for c in user_concerns):\n",
    "            multiplier *= 1.3\n",
    "        elif user_concerns:  # user specified but no match\n",
    "            multiplier *= 0.85\n",
    "\n",
    "        # Budget consideration\n",
    "        min_budget, max_budget = self._budget_range(user_budget)\n",
    "        if min_budget <= product_price <= max_budget:\n",
    "            multiplier *= 1.1\n",
    "        else:\n",
    "            multiplier *= 0.7\n",
    "\n",
    "        return max(0.3, min(multiplier, 2.0))\n",
    "\n",
    "\n",
    "\n",
    "    def enhanced_content_similarity(self, target_product_id: str, user_rated_products: List[str]) -> float:\n",
    "        \"\"\"Enhanced content similarity with multiple factors - OPTIMIZED using precomputed features\"\"\"\n",
    "        if target_product_id not in self.product_features or not user_rated_products:\n",
    "            return 0.0\n",
    "        \n",
    "        target_features = self.product_features[target_product_id]\n",
    "        target_embed = target_features['embedding']\n",
    "        target_brand = target_features['brand']\n",
    "        target_category = target_features['category']\n",
    "        target_price = target_features['price']\n",
    "        \n",
    "        similarities = []\n",
    "        \n",
    "        # Pre-filter rated products that exist in our features\n",
    "        valid_rated_products = [pid for pid in user_rated_products if pid in self.product_features]\n",
    "        \n",
    "        for rated_pid in valid_rated_products:\n",
    "            rated_features = self.product_features[rated_pid]\n",
    "            rated_embed = rated_features['embedding']\n",
    "            rated_brand = rated_features['brand']\n",
    "            rated_category = rated_features['category']\n",
    "            rated_price = rated_features['price']\n",
    "            \n",
    "            # Multiple similarity measures\n",
    "            cosine_sim = cosine_similarity([target_embed], [rated_embed])[0][0]\n",
    "            \n",
    "            # Brand similarity\n",
    "            brand_sim = 0.3 if target_brand == rated_brand else 0\n",
    "            \n",
    "            # Category similarity\n",
    "            category_sim = 0.2 if target_category == rated_category else 0\n",
    "            \n",
    "            # Price similarity (within 20% price range)\n",
    "            if target_price > 0 and rated_price > 0:\n",
    "                price_ratio = min(target_price, rated_price) / max(target_price, rated_price)\n",
    "                price_sim = 0.2 if price_ratio > 0.8 else 0\n",
    "            else:\n",
    "                price_sim = 0\n",
    "            \n",
    "            total_sim = cosine_sim + brand_sim + category_sim + price_sim\n",
    "            if total_sim > 0.3:  # Higher threshold for better quality\n",
    "                similarities.append(total_sim)\n",
    "        \n",
    "        return np.mean(similarities) if similarities else 0.0\n",
    "    \n",
    "    def get_adaptive_weights(self, user_id):\n",
    "        \"\"\"Adaptively set weights based on user activity\"\"\"\n",
    "        if user_id not in self.user_item_matrix.index:\n",
    "            return 1.0, 0.0  # fallback for new user (more content-based)\n",
    "\n",
    "        n_ratings = self.train_df[self.train_df[\"author_id\"] == user_id].shape[0]\n",
    "\n",
    "        # More ratings → trust collaborative filtering more\n",
    "        if n_ratings < 5:\n",
    "            return 0.6, 0.4   # content-heavy\n",
    "        elif n_ratings < 20:\n",
    "            return 0.4, 0.6   # balanced\n",
    "        else:\n",
    "            return 0.2, 0.8   # collab-heavy\n",
    "\n",
    "\n",
    "    def hybrid_predict(self, user_id: str, product_id: str,\n",
    "                   content_weight: float = 0.4, collab_weight: float = 0.6) -> Tuple[float, float]:\n",
    "        \"\"\"\n",
    "        Enhanced hybrid prediction with smooth adaptive weighting\n",
    "        Returns: (prediction, confidence)\n",
    "        \"\"\"\n",
    "        user_id = str(user_id)\n",
    "        product_id = str(product_id)\n",
    "        \n",
    "        # ========== SVD PREDICTION ==========\n",
    "        svd_pred = np.nan\n",
    "        svd_confidence = 0.0\n",
    "        \n",
    "        try:\n",
    "            svd_prediction = self.svd_model.predict(user_id, product_id)\n",
    "            svd_pred = max(1.0, min(5.0, svd_prediction.est))\n",
    "            svd_confidence = 0.9 if not svd_prediction.details.get('was_impossible', False) else 0.4\n",
    "        except:\n",
    "            svd_pred = self.global_avg\n",
    "            svd_confidence = 0.3\n",
    "        \n",
    "        # ========== CONTENT PREDICTION ==========\n",
    "        content_pred = np.nan\n",
    "        content_confidence = 0.0\n",
    "        \n",
    "        if user_id in self.user_history_cache:\n",
    "            user_data = self.user_history_cache[user_id]\n",
    "            rated_products = user_data['rated_products']\n",
    "            \n",
    "            if len(rated_products) >= 2 and product_id in self.product_id_to_idx:\n",
    "                similarity_score = self.enhanced_content_similarity(product_id, rated_products)\n",
    "                \n",
    "                if similarity_score > 0.1:\n",
    "                    # Map similarity to rating scale (1-5)\n",
    "                    content_pred = 1.0 + similarity_score * 4.0\n",
    "                    content_confidence = min(1.0, similarity_score * 1.8)\n",
    "                    content_pred = max(1.0, min(5.0, content_pred))\n",
    "        \n",
    "        # ========== ADVANCED HYBRID COMBINATION ==========\n",
    "        predictions = []\n",
    "        confidences = []\n",
    "        weights = []\n",
    "        \n",
    "        user_data = self.user_history_cache.get(user_id, {})\n",
    "        user_rating_count = len(user_data.get('rated_products', []))\n",
    "        \n",
    "        # Smooth scaling: more ratings → more collaborative\n",
    "        ratio = min(1.0, user_rating_count / 30)  # cap effect at 30 ratings\n",
    "        effective_collab_weight = collab_weight * (0.4 + 0.6 * ratio)  # grows with activity\n",
    "        effective_content_weight = content_weight * (1.0 - 0.6 * ratio)  # shrinks with activity\n",
    "        \n",
    "        if not np.isnan(svd_pred):\n",
    "            predictions.append(svd_pred)\n",
    "            confidences.append(svd_confidence)\n",
    "            weights.append(effective_collab_weight)\n",
    "        \n",
    "        if not np.isnan(content_pred) and content_confidence > 0.2:\n",
    "            predictions.append(content_pred)\n",
    "            confidences.append(content_confidence)\n",
    "            weights.append(effective_content_weight)\n",
    "        \n",
    "        if len(predictions) == 2:\n",
    "            total_confidence = sum(c * w for c, w in zip(confidences, weights))\n",
    "            weighted_pred = sum(p * c * w for p, c, w in zip(predictions, confidences, weights)) / total_confidence\n",
    "            final_confidence = total_confidence / sum(weights)\n",
    "        elif len(predictions) == 1:\n",
    "            weighted_pred = predictions[0]\n",
    "            final_confidence = confidences[0]\n",
    "        else:\n",
    "            # Fallback: use user's avg rating or global avg with small jitter\n",
    "            weighted_pred = user_data.get('avg_rating', self.global_avg) + np.random.uniform(-0.2, 0.2)\n",
    "            weighted_pred = max(1.0, min(5.0, weighted_pred))\n",
    "            final_confidence = 0.2\n",
    "        \n",
    "        return max(1.0, min(5.0, weighted_pred)), final_confidence\n",
    "\n",
    "    def calculate_match_percentage(self, score: float, user_id: str, product_id: str, \n",
    "                             all_recommendation_scores: List[float] = None) -> int:\n",
    "        \"\"\"Improved match percentage with relative scoring\"\"\"\n",
    "        \n",
    "        if all_recommendation_scores:\n",
    "            # Use percentile ranking within current recommendations\n",
    "            sorted_scores = sorted(all_recommendation_scores)\n",
    "            position = sorted_scores.index(score)\n",
    "            percentile = (position / len(sorted_scores)) * 100\n",
    "            return int(percentile)\n",
    "        else:\n",
    "            # Fallback to original method\n",
    "            user_data = self.user_history_cache.get(str(user_id), {})\n",
    "            user_avg = user_data.get('avg_rating', self.global_avg)\n",
    "            \n",
    "            # Adjust based on user's rating behavior\n",
    "            if user_avg >= 4.0:\n",
    "                match_percent = min(100, max(0, (score - 2.8) / 2.2 * 100))\n",
    "            elif user_avg <= 2.5:\n",
    "                match_percent = min(100, max(0, (score - 1.8) / 3.2 * 100))\n",
    "            else:\n",
    "                if score >= 3.5:\n",
    "                    match_percent = 70 + (score - 3.5) / 1.5 * 30\n",
    "                elif score >= 2.5:\n",
    "                    match_percent = 40 + (score - 2.5) / 1.0 * 30\n",
    "                else:\n",
    "                    match_percent = max(0, score / 2.5 * 40)\n",
    "            \n",
    "            return int(match_percent)\n",
    "\n",
    "    def calculate_diversity_penalty(self, target_product_id: str, current_recommendations: List[Tuple]) -> float:\n",
    "        \"\"\"Penalize products too similar to already recommended ones\"\"\"\n",
    "        if not current_recommendations or target_product_id not in self.product_id_to_idx:\n",
    "            return 0.0\n",
    "        \n",
    "        target_idx = self.product_id_to_idx[target_product_id]\n",
    "        target_embed = self.prod_embeds[target_idx]\n",
    "        \n",
    "        max_similarity = 0.0\n",
    "        for recommendation in current_recommendations:\n",
    "            # Handle different tuple formats\n",
    "            if len(recommendation) >= 2:\n",
    "                rec_product_id = recommendation[0]\n",
    "            else:\n",
    "                continue\n",
    "                \n",
    "            if rec_product_id in self.product_id_to_idx:\n",
    "                rec_idx = self.product_id_to_idx[rec_product_id]\n",
    "                rec_embed = self.prod_embeds[rec_idx]\n",
    "                sim = cosine_similarity([target_embed], [rec_embed])[0][0]\n",
    "                max_similarity = max(max_similarity, sim)\n",
    "        \n",
    "        # Penalize if too similar to existing recommendations\n",
    "        return max_similarity * 0.4  # 40% penalty for high similarity\n",
    "\n",
    "    def generate_recommendations(self, user_id: str, top_n: int = 10, \n",
    "                             content_weight: float = 0.4, collab_weight: float = 0.6,\n",
    "                             min_confidence: float = 0.5) -> List[Tuple[str, float, int]]:\n",
    "        \"\"\"\n",
    "        Generate enhanced recommendations with confidence filtering\n",
    "        Returns: List of (product_id, predicted_rating, match_percentage)\n",
    "        \"\"\"\n",
    "        user_id = str(user_id)\n",
    "        user_rated = self.user_history_cache.get(user_id, {}).get('rated_products', [])\n",
    "        \n",
    "        all_products = self.prod_df[\"product_id\"].astype(str).tolist()\n",
    "        candidate_products = [pid for pid in all_products if pid not in user_rated]\n",
    "        \n",
    "        if not candidate_products:\n",
    "            return self._get_popular_fallback(top_n)\n",
    "        \n",
    "        recommendations = []\n",
    "        \n",
    "        for product_id in tqdm(candidate_products, desc=\"Predicting ratings\"):\n",
    "            try:\n",
    "                predicted_rating, confidence = self.hybrid_predict(user_id, product_id, content_weight, collab_weight)\n",
    "                match_percent = self.calculate_match_percentage(predicted_rating, user_id, product_id)\n",
    "                \n",
    "                skin_match = self.filter_by_skin_profile(product_id, user_id)\n",
    "                adjusted_rating = predicted_rating * skin_match\n",
    "                adjusted_confidence = confidence * skin_match\n",
    "                \n",
    "                match_percent = self.calculate_match_percentage(adjusted_rating, user_id, product_id)\n",
    "                \n",
    "                if adjusted_confidence >= min_confidence and match_percent >= 40:\n",
    "                    recommendations.append((product_id, adjusted_rating, match_percent))\n",
    "            except Exception:\n",
    "                continue\n",
    "        \n",
    "        # ✅ Sort by hybrid predicted rating directly (no reranking)\n",
    "        recommendations.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        return recommendations[:top_n]\n",
    "\n",
    "    def _get_popular_fallback(self, top_n: int) -> List[Tuple[str, float, int]]:\n",
    "        \"\"\"Fallback to popular products\"\"\"\n",
    "        popular_products = self.test_df.groupby('product_id')['rating'].agg(['count', 'mean']).reset_index()\n",
    "        popular_products = popular_products[popular_products['count'] >= 10]  # Only reasonably popular\n",
    "        popular_products = popular_products.sort_values(['mean', 'count'], ascending=False)\n",
    "        \n",
    "        result = []\n",
    "        for _, row in popular_products.head(top_n).iterrows():\n",
    "            product_id = str(row['product_id'])\n",
    "            score = row['mean']\n",
    "            match_percent = self.calculate_match_percentage(score, \"average_user\", product_id)\n",
    "            result.append((product_id, score, match_percent))\n",
    "        \n",
    "        return result\n",
    "\n",
    "    def enhanced_demo_recommendations(self, user_id: str, top_n: int = 5,\n",
    "                                   content_weight: float = 0.4, collab_weight: float = 0.6):\n",
    "        \"\"\"Show enhanced recommendations with explanations\"\"\"\n",
    "        recommendations = self.generate_recommendations(user_id, top_n * 2, content_weight, collab_weight)\n",
    "        \n",
    "        print(f\"\\n🎯 ENHANCED RECOMMENDATIONS FOR USER {user_id}:\")\n",
    "        print(f\"   Weights: Content={content_weight}, SVD={collab_weight}\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        user_data = self.user_history_cache.get(str(user_id), {})\n",
    "        user_avg = user_data.get('avg_rating', self.global_avg)\n",
    "        \n",
    "        displayed = 0\n",
    "        for i, (product_id, score, match_percent) in enumerate(recommendations, 1):\n",
    "            if displayed >= top_n:\n",
    "                break\n",
    "                \n",
    "            product_info = self.prod_df[self.prod_df[\"product_id\"].astype(str) == product_id]\n",
    "            if product_info.empty:\n",
    "                continue\n",
    "                \n",
    "            product_info = product_info.iloc[0]\n",
    "            name = product_info[\"product_name\"]\n",
    "            brand = product_info[\"brand_name\"]\n",
    "            category = product_info[\"tertiary_category\"]\n",
    "            price = product_info[\"price_usd\"]\n",
    "            \n",
    "            formatted_price = f\"${price:.2f}\" if isinstance(price, (int, float)) else f\"${price}\"\n",
    "            \n",
    "            print(f\"{displayed + 1}. {name} ({brand})\")\n",
    "            print(f\"   📍 {category} • 💰 {formatted_price}\")\n",
    "            print(f\"   ⭐ {score:.4f}/5 • 🔍 {match_percent}% match\")\n",
    "            print(f\"   🆔 {product_id}\")\n",
    "            \n",
    "            # Add intelligent explanation\n",
    "            if score >= 4.2:\n",
    "                print(\"   💎 Excellent match! Based on your preferences and highly rated by similar users\")\n",
    "            elif score >= 3.8:\n",
    "                print(\"   👍 Great match - combines your product preferences with crowd wisdom\")\n",
    "            elif score >= 3.2:\n",
    "                print(\"   🔍 Good suggestion - users with similar tastes enjoyed this product\")\n",
    "            elif score >= 2.8:\n",
    "                print(\"   💡 Recommended - similar to products you've liked, worth exploring\")\n",
    "            else:\n",
    "                print(\"   🌟 New discovery - different from your usual preferences but highly rated\")\n",
    "            \n",
    "            print()\n",
    "            displayed += 1\n",
    "        \n",
    "        if displayed == 0:\n",
    "            print(\"⚠️  No confident recommendations found. Try rating more products!\")\n",
    "            print(\"💡 Exploring new categories might help improve recommendations\")\n",
    "        \n",
    "    def evaluate(self, top_n: int = 10,\n",
    "                content_weight: float = 0.4, collab_weight: float = 0.6,\n",
    "                min_confidence: float = 0.0) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Evaluate recommender on test dataset with multiple metrics:\n",
    "        - RMSE, MAE\n",
    "        - Accuracy (binary hit if predicted >= 3.5 matches actual >= 3.5)\n",
    "        - Precision, Recall, F1\n",
    "        - Coverage (how many unique products were recommended)\n",
    "        \"\"\"\n",
    "        print(\"\\n📊 Evaluating recommender system...\")\n",
    "\n",
    "        y_true, y_pred = [], []\n",
    "        hit_count, rec_count, relevant_count = 0, 0, 0\n",
    "        recommended_products = set()\n",
    "\n",
    "        for _, row in tqdm(self.test_df.iterrows(), total=len(self.test_df), desc=\"Evaluating\"):\n",
    "            user_id, product_id, actual_rating = str(row[\"author_id\"]), str(row[\"product_id\"]), row[\"rating\"]\n",
    "\n",
    "            try:\n",
    "                pred_rating, confidence = self.hybrid_predict(user_id, product_id,\n",
    "                                                            content_weight, collab_weight)\n",
    "                # if confidence < min_confidence:\n",
    "                #     continue\n",
    "\n",
    "                y_true.append(actual_rating)\n",
    "                y_pred.append(pred_rating)\n",
    "\n",
    "                # --- Binary relevance for classification metrics ---\n",
    "                actual_relevant = 1 if actual_rating >= 3.5 else 0\n",
    "                predicted_relevant = 1 if pred_rating >= 3.5 else 0\n",
    "\n",
    "                if predicted_relevant == 1:\n",
    "                    rec_count += 1\n",
    "                    recommended_products.add(product_id)\n",
    "\n",
    "                if actual_relevant == 1:\n",
    "                    relevant_count += 1\n",
    "\n",
    "                if predicted_relevant == 1 and actual_relevant == 1:\n",
    "                    hit_count += 1\n",
    "\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "        # --- Compute metrics ---\n",
    "        rmse = np.sqrt(mean_squared_error(y_true, y_pred)) if y_true else float(\"nan\")\n",
    "        mae = mean_absolute_error(y_true, y_pred) if y_true else float(\"nan\")\n",
    "        accuracy = accuracy_score([1 if r >= 3.5 else 0 for r in y_true],\n",
    "                                [1 if p >= 3.5 else 0 for p in y_pred]) if y_true else float(\"nan\")\n",
    "        precision = precision_score([1 if r >= 3.5 else 0 for r in y_true],\n",
    "                                    [1 if p >= 3.5 else 0 for p in y_pred],\n",
    "                                    zero_division=0) if y_true else float(\"nan\")\n",
    "        recall = recall_score([1 if r >= 3.5 else 0 for r in y_true],\n",
    "                            [1 if p >= 3.5 else 0 for p in y_pred],\n",
    "                            zero_division=0) if y_true else float(\"nan\")\n",
    "        f1 = f1_score([1 if r >= 3.5 else 0 for r in y_true],\n",
    "                    [1 if p >= 3.5 else 0 for p in y_pred],\n",
    "                    zero_division=0) if y_true else float(\"nan\")\n",
    "\n",
    "        coverage = len(recommended_products) / len(self.prod_df) if len(self.prod_df) > 0 else 0\n",
    "\n",
    "        results = {\n",
    "            \"RMSE\": rmse,\n",
    "            \"MAE\": mae,\n",
    "            \"Accuracy\": accuracy,\n",
    "            \"Precision\": precision,\n",
    "            \"Recall\": recall,\n",
    "            \"F1\": f1,\n",
    "            \"Coverage\": coverage\n",
    "        }\n",
    "\n",
    "        print(\"\\n📈 Evaluation Results:\")\n",
    "        for metric, value in results.items():\n",
    "            print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "        return results     \n",
    "    def evaluate_by_user_group(self, top_n=10):\n",
    "        \"\"\"\n",
    "        Evaluate recommender performance across user groups:\n",
    "        - Cold-start (<5 ratings)\n",
    "        - Medium (5-20 ratings)\n",
    "        - Heavy (>20 ratings)\n",
    "        \"\"\"\n",
    "        # Count ratings per user from training data\n",
    "        user_rating_counts = self.train_df.groupby(\"author_id\")[\"rating\"].count().to_dict()\n",
    "        \n",
    "        groups = {\n",
    "            \"Cold-start (<5)\": [],\n",
    "            \"Medium (5-20)\": [],\n",
    "            \"Heavy (>20)\": []\n",
    "        }\n",
    "\n",
    "        for _, row in self.test_df.iterrows():\n",
    "            user = str(row[\"author_id\"])\n",
    "            item = str(row[\"product_id\"])\n",
    "            true_rating = row[\"rating\"]\n",
    "\n",
    "            pred_rating, _ = self.hybrid_predict(user, item)\n",
    "\n",
    "            # Assign to group\n",
    "            count = user_rating_counts.get(user, 0)\n",
    "            if count < 5:\n",
    "                group = \"Cold-start (<5)\"\n",
    "            elif count > 20:\n",
    "                group = \"Heavy (>20)\"\n",
    "            else:\n",
    "                group = \"Medium (5-20)\"\n",
    "\n",
    "            groups[group].append((true_rating, pred_rating))\n",
    "\n",
    "        results = {}\n",
    "        for group, values in groups.items():\n",
    "            if not values:\n",
    "                continue\n",
    "            y_true, y_pred = zip(*values)\n",
    "            rmse = sqrt(mean_squared_error(y_true, y_pred))\n",
    "            mae = mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "            y_true_bin = [1 if r >= 4 else 0 for r in y_true]\n",
    "            y_pred_bin = [1 if p >= 4 else 0 for p in y_pred]\n",
    "\n",
    "            precision = precision_score(y_true_bin, y_pred_bin, zero_division=0)\n",
    "            recall = recall_score(y_true_bin, y_pred_bin, zero_division=0)\n",
    "            f1 = f1_score(y_true_bin, y_pred_bin, zero_division=0)\n",
    "            acc = accuracy_score(y_true_bin, y_pred_bin)\n",
    "\n",
    "            results[group] = {\n",
    "                \"RMSE\": rmse,\n",
    "                \"MAE\": mae,\n",
    "                \"Accuracy\": acc,\n",
    "                \"Precision\": precision,\n",
    "                \"Recall\": recall,\n",
    "                \"F1\": f1,\n",
    "                \"Count\": len(values)\n",
    "            }\n",
    "\n",
    "        results_df = pd.DataFrame(results).T\n",
    "        print(\"\\n📊 Evaluation by User Group:\")\n",
    "        print(results_df)\n",
    "        return results_df\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    print(\"🚀 INITIALIZING ENHANCED HYBRID RECOMMENDER\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # Initialize recommender\n",
    "    recommender = EnhancedHybridRecommender(\n",
    "        train_path=\"data/CleanedDataSet/train_skincare.csv\",\n",
    "        test_path=\"data/CleanedDataSet/test_skincare.csv\",\n",
    "        products_path=\"data/CleanedDataSet/filtered_skincare_products.csv\",\n",
    "        content_model_path=\"models/product_embeddings.pkl\",\n",
    "        svd_model_path=\"models/surprise_svd_model.pkl\"\n",
    "    )\n",
    "\n",
    "    print(\"\\n✅ ENHANCED INITIALIZATION COMPLETE!\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # 🔹 Fixed best weights for assignment\n",
    "    best_content_weight = 0.2\n",
    "    best_collab_weight = 0.8\n",
    "\n",
    "    # ---------------- 3) Generate recommendations for a real user ----------------\n",
    "    real_user_id = 2128891661  # <-- must exist in your dataset\n",
    "    recommender.enhanced_demo_recommendations(\n",
    "        user_id=real_user_id,\n",
    "        top_n=5,\n",
    "        content_weight=best_content_weight,\n",
    "        collab_weight=best_collab_weight\n",
    "    )\n",
    "\n",
    "    # ---------------- 4) Evaluate system ----------------\n",
    "    eval_results = recommender.evaluate(\n",
    "        top_n=10,\n",
    "        content_weight=best_content_weight,\n",
    "        collab_weight=best_collab_weight\n",
    "    )\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
