{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac12593c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 INITIALIZING ENHANCED HYBRID RECOMMENDER\n",
      "================================================================================\n",
      "📦 Loading pre-trained models...\n",
      "✅ Content model loaded: 1760 products\n",
      "✅ SVD model loaded\n",
      "📈 Global average rating from SVD: 3.934\n",
      "✅ Index mappings created\n",
      "⚡ Precomputing product features for faster similarity...\n",
      "✅ Precomputed features for 1760 products\n",
      "📊 Preloading data...\n",
      "✅ Test data loaded: 160291 records\n",
      "✅ Train data loaded: 641164 records\n",
      "🔨 Building user history cache...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caching user histories: 100%|██████████| 430159/430159 [00:43<00:00, 9939.51it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Calculating product popularity...\n",
      "=== Dataset Overview ===\n",
      "Train set: 641,164 rows | 357,909 users | 1,760 products\n",
      "Test set: 160,291 rows | 131,518 users | 1,705 products\n",
      "Products catalog: 1,760 items\n",
      "========================\n",
      "✅ Enhanced Hybrid Recommender initialized successfully!\n",
      "\n",
      "✅ ENHANCED INITIALIZATION COMPLETE!\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting ratings: 100%|██████████| 1752/1752 [00:02<00:00, 600.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎯 ENHANCED RECOMMENDATIONS FOR USER 2128891661:\n",
      "   Weights: Content=0.2, SVD=0.8\n",
      "================================================================================\n",
      "1. Vitamin Enriched Face Base Jumbo (Bobbi Brown)\n",
      "   📍 Moisturizers • 💰 $99.00\n",
      "   ⭐ 4.3350/5 • 🔍 86% match\n",
      "   🆔 P468634\n",
      "   💎 Excellent match! Based on your preferences and highly rated by similar users\n",
      "\n",
      "2. Ultra Repair Firming Collagen Cream with Peptides and Niacinamide (First Aid Beauty)\n",
      "   📍 Moisturizers • 💰 $44.00\n",
      "   ⭐ 4.2842/5 • 🔍 85% match\n",
      "   🆔 P468821\n",
      "   💎 Excellent match! Based on your preferences and highly rated by similar users\n",
      "\n",
      "3. Resveratrol Lift Retinol Alternative Firming Cashmere Moisturizer (Caudalie)\n",
      "   📍 Moisturizers • 💰 $69.00\n",
      "   ⭐ 4.2702/5 • 🔍 85% match\n",
      "   🆔 P467750\n",
      "   💎 Excellent match! Based on your preferences and highly rated by similar users\n",
      "\n",
      "4. Absolue Rich Cream Moisturizer (Lancôme)\n",
      "   📍 Moisturizers • 💰 $270.00\n",
      "   ⭐ 4.2571/5 • 🔍 85% match\n",
      "   🆔 P482025\n",
      "   💎 Excellent match! Based on your preferences and highly rated by similar users\n",
      "\n",
      "5. Hydra Vizor Invisible Moisturizer Broad Spectrum SPF 30 Sunscreen with Niacinamide Refill (Fenty Skin)\n",
      "   📍 Moisturizers • 💰 $35.00\n",
      "   ⭐ 4.2531/5 • 🔍 85% match\n",
      "   🆔 P476485\n",
      "   💎 Excellent match! Based on your preferences and highly rated by similar users\n",
      "\n",
      "\n",
      "📊 Evaluating recommender system...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 160291/160291 [04:09<00:00, 641.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📈 Evaluation Results:\n",
      "RMSE: 0.9711\n",
      "MAE: 0.7986\n",
      "Accuracy: 0.8682\n",
      "Precision: 0.8679\n",
      "Recall: 0.9914\n",
      "F1: 0.9255\n",
      "Coverage: 0.9631\n",
      "\n",
      "📊 Evaluation by User Group:\n",
      "                     RMSE       MAE  Accuracy  Precision    Recall        F1  \\\n",
      "Cold-start (<5)  1.051506  0.820514  0.747102   0.877615  0.800743  0.837418   \n",
      "Medium (5-20)    0.890767  0.678058  0.874807   0.890803  0.972494  0.929858   \n",
      "Heavy (>20)      0.686356  0.583615  0.903208   0.974260  0.920285  0.946504   \n",
      "\n",
      "                    Count  \n",
      "Cold-start (<5)  127419.0  \n",
      "Medium (5-20)     23987.0  \n",
      "Heavy (>20)        8885.0  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from math import sqrt\n",
    "from tqdm import tqdm\n",
    "import joblib\n",
    "from typing import Dict, List, Tuple\n",
    "from surprise import dump\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class EnhancedHybridRecommender:\n",
    "    def __init__(self, train_path: str, test_path: str, products_path: str,\n",
    "                 content_model_path: str, svd_model_path: str):\n",
    "        \"\"\"\n",
    "        Hybrid Recommender: SVD + Content-based filtering with improvements\n",
    "        \"\"\"\n",
    "        self.train_path = train_path\n",
    "        self.test_path = test_path\n",
    "        self.products_path = products_path\n",
    "        self.content_model_path = content_model_path\n",
    "        self.svd_model_path = svd_model_path\n",
    "        \n",
    "        # Initialize attributes\n",
    "        self.prod_df = None\n",
    "        self.prod_embeds = None\n",
    "        self.svd_model = None\n",
    "        self.global_avg = 3.0\n",
    "        self.test_df = None\n",
    "        self.train_df = None\n",
    "        self.user_history_cache = {}\n",
    "        self.product_popularity = {}\n",
    "        self.product_features = {}\n",
    "        \n",
    "        # Load models and data\n",
    "        self._load_models()\n",
    "        self._preload_data()\n",
    "        \n",
    "        print(\"✅ Enhanced Hybrid Recommender initialized successfully!\")\n",
    "\n",
    "    def _load_models(self) -> None:\n",
    "        \"\"\"Load pre-trained models\"\"\"\n",
    "        print(\"📦 Loading pre-trained models...\")\n",
    "        \n",
    "        # Load content-based model\n",
    "        if os.path.exists(self.content_model_path):\n",
    "            self.prod_df, self.prod_embeds = joblib.load(self.content_model_path)\n",
    "            print(f\"✅ Content model loaded: {len(self.prod_df)} products\")\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"Content model not found at {self.content_model_path}\")\n",
    "        \n",
    "        # Load SVD model\n",
    "        if os.path.exists(self.svd_model_path):\n",
    "            _, self.svd_model = dump.load(self.svd_model_path)\n",
    "            print(\"✅ SVD model loaded\")\n",
    "            \n",
    "            # Get global average from SVD\n",
    "            if hasattr(self.svd_model, 'trainset') and self.svd_model.trainset:\n",
    "                self.global_avg = self.svd_model.trainset.global_mean\n",
    "                print(f\"📈 Global average rating from SVD: {self.global_avg:.3f}\")\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"SVD model not found at {self.svd_model_path}\")\n",
    "        \n",
    "        # Create index mappings\n",
    "        self.product_id_to_idx = {str(pid): idx for idx, pid in enumerate(self.prod_df[\"product_id\"])}\n",
    "        print(\"✅ Index mappings created\")\n",
    "        \n",
    "        # Precompute product features for faster similarity calculation\n",
    "        self.precompute_product_features()\n",
    "\n",
    "    def precompute_product_features(self):\n",
    "        \"\"\"Precompute product features for faster similarity calculation\"\"\"\n",
    "        print(\"⚡ Precomputing product features for faster similarity...\")\n",
    "        \n",
    "        self.product_features = {}\n",
    "        for _, row in self.prod_df.iterrows():\n",
    "            product_id = str(row[\"product_id\"])\n",
    "            self.product_features[product_id] = {\n",
    "                'brand': row[\"brand_name\"],\n",
    "                'category': row[\"tertiary_category\"],\n",
    "                'price': row[\"price_usd\"] if pd.notna(row[\"price_usd\"]) else 0,\n",
    "                'embedding': self.prod_embeds[self.product_id_to_idx[product_id]]\n",
    "            }\n",
    "        \n",
    "        print(f\"✅ Precomputed features for {len(self.product_features)} products\")\n",
    "\n",
    "    def _preload_data(self):\n",
    "        print(\"📊 Preloading data...\")\n",
    "\n",
    "        # Load a small sample just to detect available columns\n",
    "        test_sample = pd.read_csv(self.test_path, nrows=5)\n",
    "\n",
    "        # Base columns we always need\n",
    "        usecols = [\"author_id\", \"product_id\", \"rating\"]\n",
    "\n",
    "        # ✅ Try to detect a timestamp column from the sample\n",
    "        time_col = None\n",
    "        for col in [\"timestamp\", \"submission_time\", \"review_date\"]:\n",
    "            if col in test_sample.columns:\n",
    "                time_col = col\n",
    "                usecols.append(col)\n",
    "                break\n",
    "\n",
    "        # Load full test/train datasets with only needed columns\n",
    "        self.test_df = pd.read_csv(self.test_path, usecols=usecols)\n",
    "        self.train_df = pd.read_csv(self.train_path, usecols=[\"author_id\", \"product_id\", \"rating\"])\n",
    "\n",
    "        # Build user history cache (from train)\n",
    "        self.user_histories = (\n",
    "            self.train_df.groupby(\"author_id\")[\"product_id\"].apply(list).to_dict()\n",
    "        )\n",
    "\n",
    "        print(f\"✅ Test data loaded: {len(self.test_df)} records\")\n",
    "        print(f\"✅ Train data loaded: {len(self.train_df)} records\")\n",
    "\n",
    "        \n",
    "        # Build user history cache - OPTIMIZED\n",
    "        print(\"🔨 Building user history cache...\")\n",
    "        all_ratings = pd.concat([self.train_df, self.test_df])\n",
    "        \n",
    "        # Use groupby for faster processing\n",
    "        user_groups = all_ratings.groupby(\"author_id\")\n",
    "        for user_id, group in tqdm(user_groups, desc=\"Caching user histories\"):\n",
    "            self.user_history_cache[str(user_id)] = {\n",
    "                'rated_products': group[\"product_id\"].astype(str).tolist(),\n",
    "                'ratings': group[\"rating\"].tolist(),\n",
    "                'avg_rating': group[\"rating\"].mean()\n",
    "            }\n",
    "        \n",
    "        # Calculate product popularity\n",
    "        print(\"📊 Calculating product popularity...\")\n",
    "        # FIXED: Changed ast(str) to astype(str)\n",
    "        self.product_popularity = all_ratings['product_id'].astype(str).value_counts().to_dict()\n",
    "        \n",
    "        print(\"=== Dataset Overview ===\")\n",
    "        print(f\"Train set: {len(self.train_df):,} rows | {self.train_df['author_id'].nunique():,} users | {self.train_df['product_id'].nunique():,} products\")\n",
    "        print(f\"Test set: {len(self.test_df):,} rows | {self.test_df['author_id'].nunique():,} users | {self.test_df['product_id'].nunique():,} products\")\n",
    "        print(f\"Products catalog: {len(self.prod_df):,} items\")\n",
    "        print(\"========================\")\n",
    "\n",
    "    def enhanced_content_similarity(self, target_product_id: str, user_rated_products: List[str]) -> float:\n",
    "        \"\"\"Enhanced content similarity with multiple factors - OPTIMIZED using precomputed features\"\"\"\n",
    "        if target_product_id not in self.product_features or not user_rated_products:\n",
    "            return 0.0\n",
    "        \n",
    "        target_features = self.product_features[target_product_id]\n",
    "        target_embed = target_features['embedding']\n",
    "        target_brand = target_features['brand']\n",
    "        target_category = target_features['category']\n",
    "        target_price = target_features['price']\n",
    "        \n",
    "        similarities = []\n",
    "        \n",
    "        # Pre-filter rated products that exist in our features\n",
    "        valid_rated_products = [pid for pid in user_rated_products if pid in self.product_features]\n",
    "        \n",
    "        for rated_pid in valid_rated_products:\n",
    "            rated_features = self.product_features[rated_pid]\n",
    "            rated_embed = rated_features['embedding']\n",
    "            rated_brand = rated_features['brand']\n",
    "            rated_category = rated_features['category']\n",
    "            rated_price = rated_features['price']\n",
    "            \n",
    "            # Multiple similarity measures\n",
    "            cosine_sim = cosine_similarity([target_embed], [rated_embed])[0][0]\n",
    "            \n",
    "            # Brand similarity\n",
    "            brand_sim = 0.3 if target_brand == rated_brand else 0\n",
    "            \n",
    "            # Category similarity\n",
    "            category_sim = 0.2 if target_category == rated_category else 0\n",
    "            \n",
    "            # Price similarity (within 20% price range)\n",
    "            if target_price > 0 and rated_price > 0:\n",
    "                price_ratio = min(target_price, rated_price) / max(target_price, rated_price)\n",
    "                price_sim = 0.2 if price_ratio > 0.8 else 0\n",
    "            else:\n",
    "                price_sim = 0\n",
    "            \n",
    "            total_sim = cosine_sim + brand_sim + category_sim + price_sim\n",
    "            if total_sim > 0.3:  # Higher threshold for better quality\n",
    "                similarities.append(total_sim)\n",
    "        \n",
    "        return np.mean(similarities) if similarities else 0.0\n",
    "    \n",
    "    def get_adaptive_weights(self, user_id):\n",
    "        \"\"\"Adaptively set weights based on user activity\"\"\"\n",
    "        if user_id not in self.user_item_matrix.index:\n",
    "            return 0.6, 0.4  # fallback for new user (more content-based)\n",
    "\n",
    "        n_ratings = self.train_df[self.train_df[\"author_id\"] == user_id].shape[0]\n",
    "\n",
    "        # More ratings → trust collaborative filtering more\n",
    "        if n_ratings < 5:\n",
    "            return 0.6, 0.4   # content-heavy\n",
    "        elif n_ratings < 20:\n",
    "            return 0.4, 0.6   # balanced\n",
    "        else:\n",
    "            return 0.2, 0.8   # collab-heavy\n",
    "\n",
    "\n",
    "    def hybrid_predict(self, user_id: str, product_id: str,\n",
    "                   content_weight: float = 0.4, collab_weight: float = 0.6) -> Tuple[float, float]:\n",
    "        \"\"\"\n",
    "        Enhanced hybrid prediction with smooth adaptive weighting\n",
    "        Returns: (prediction, confidence)\n",
    "        \"\"\"\n",
    "        user_id = str(user_id)\n",
    "        product_id = str(product_id)\n",
    "        \n",
    "        # ========== SVD PREDICTION ==========\n",
    "        svd_pred = np.nan\n",
    "        svd_confidence = 0.0\n",
    "        \n",
    "        try:\n",
    "            svd_prediction = self.svd_model.predict(user_id, product_id)\n",
    "            svd_pred = max(1.0, min(5.0, svd_prediction.est))\n",
    "            svd_confidence = 0.9 if not svd_prediction.details.get('was_impossible', False) else 0.4\n",
    "        except:\n",
    "            svd_pred = self.global_avg\n",
    "            svd_confidence = 0.3\n",
    "        \n",
    "        # ========== CONTENT PREDICTION ==========\n",
    "        content_pred = np.nan\n",
    "        content_confidence = 0.0\n",
    "        \n",
    "        if user_id in self.user_history_cache:\n",
    "            user_data = self.user_history_cache[user_id]\n",
    "            rated_products = user_data['rated_products']\n",
    "            \n",
    "            if len(rated_products) >= 2 and product_id in self.product_id_to_idx:\n",
    "                similarity_score = self.enhanced_content_similarity(product_id, rated_products)\n",
    "                \n",
    "                if similarity_score > 0.1:\n",
    "                    # Map similarity to rating scale (1-5)\n",
    "                    content_pred = 1.0 + similarity_score * 4.0\n",
    "                    content_confidence = min(1.0, similarity_score * 1.8)\n",
    "                    content_pred = max(1.0, min(5.0, content_pred))\n",
    "        \n",
    "        # ========== ADVANCED HYBRID COMBINATION ==========\n",
    "        predictions = []\n",
    "        confidences = []\n",
    "        weights = []\n",
    "        \n",
    "        user_data = self.user_history_cache.get(user_id, {})\n",
    "        user_rating_count = len(user_data.get('rated_products', []))\n",
    "        \n",
    "        # Smooth scaling: more ratings → more collaborative\n",
    "        ratio = min(1.0, user_rating_count / 30)  # cap effect at 30 ratings\n",
    "        effective_collab_weight = collab_weight * (0.4 + 0.6 * ratio)  # grows with activity\n",
    "        effective_content_weight = content_weight * (1.0 - 0.6 * ratio)  # shrinks with activity\n",
    "        \n",
    "        if not np.isnan(svd_pred):\n",
    "            predictions.append(svd_pred)\n",
    "            confidences.append(svd_confidence)\n",
    "            weights.append(effective_collab_weight)\n",
    "        \n",
    "        if not np.isnan(content_pred) and content_confidence > 0.2:\n",
    "            predictions.append(content_pred)\n",
    "            confidences.append(content_confidence)\n",
    "            weights.append(effective_content_weight)\n",
    "        \n",
    "        if len(predictions) == 2:\n",
    "            total_confidence = sum(c * w for c, w in zip(confidences, weights))\n",
    "            weighted_pred = sum(p * c * w for p, c, w in zip(predictions, confidences, weights)) / total_confidence\n",
    "            final_confidence = total_confidence / sum(weights)\n",
    "        elif len(predictions) == 1:\n",
    "            weighted_pred = predictions[0]\n",
    "            final_confidence = confidences[0]\n",
    "        else:\n",
    "            # Fallback: use user's avg rating or global avg with small jitter\n",
    "            weighted_pred = user_data.get('avg_rating', self.global_avg) + np.random.uniform(-0.2, 0.2)\n",
    "            weighted_pred = max(1.0, min(5.0, weighted_pred))\n",
    "            final_confidence = 0.2\n",
    "        \n",
    "        return max(1.0, min(5.0, weighted_pred)), final_confidence\n",
    "\n",
    "    def calculate_match_percentage(self, score: float, user_id: str, product_id: str, \n",
    "                             all_recommendation_scores: List[float] = None) -> int:\n",
    "        \"\"\"Improved match percentage with relative scoring\"\"\"\n",
    "        \n",
    "        if all_recommendation_scores:\n",
    "            # Use percentile ranking within current recommendations\n",
    "            sorted_scores = sorted(all_recommendation_scores)\n",
    "            position = sorted_scores.index(score)\n",
    "            percentile = (position / len(sorted_scores)) * 100\n",
    "            return int(percentile)\n",
    "        else:\n",
    "            # Fallback to original method\n",
    "            user_data = self.user_history_cache.get(str(user_id), {})\n",
    "            user_avg = user_data.get('avg_rating', self.global_avg)\n",
    "            \n",
    "            # Adjust based on user's rating behavior\n",
    "            if user_avg >= 4.0:\n",
    "                match_percent = min(100, max(0, (score - 2.8) / 2.2 * 100))\n",
    "            elif user_avg <= 2.5:\n",
    "                match_percent = min(100, max(0, (score - 1.8) / 3.2 * 100))\n",
    "            else:\n",
    "                if score >= 3.5:\n",
    "                    match_percent = 70 + (score - 3.5) / 1.5 * 30\n",
    "                elif score >= 2.5:\n",
    "                    match_percent = 40 + (score - 2.5) / 1.0 * 30\n",
    "                else:\n",
    "                    match_percent = max(0, score / 2.5 * 40)\n",
    "            \n",
    "            return int(match_percent)\n",
    "\n",
    "    def calculate_diversity_penalty(self, target_product_id: str, current_recommendations: List[Tuple]) -> float:\n",
    "        \"\"\"Penalize products too similar to already recommended ones\"\"\"\n",
    "        if not current_recommendations or target_product_id not in self.product_id_to_idx:\n",
    "            return 0.0\n",
    "        \n",
    "        target_idx = self.product_id_to_idx[target_product_id]\n",
    "        target_embed = self.prod_embeds[target_idx]\n",
    "        \n",
    "        max_similarity = 0.0\n",
    "        for recommendation in current_recommendations:\n",
    "            # Handle different tuple formats\n",
    "            if len(recommendation) >= 2:\n",
    "                rec_product_id = recommendation[0]\n",
    "            else:\n",
    "                continue\n",
    "                \n",
    "            if rec_product_id in self.product_id_to_idx:\n",
    "                rec_idx = self.product_id_to_idx[rec_product_id]\n",
    "                rec_embed = self.prod_embeds[rec_idx]\n",
    "                sim = cosine_similarity([target_embed], [rec_embed])[0][0]\n",
    "                max_similarity = max(max_similarity, sim)\n",
    "        \n",
    "        # Penalize if too similar to existing recommendations\n",
    "        return max_similarity * 0.4  # 40% penalty for high similarity\n",
    "\n",
    "    def generate_recommendations(self, user_id: str, top_n: int = 10, \n",
    "                             content_weight: float = 0.4, collab_weight: float = 0.6,\n",
    "                             min_confidence: float = 0.5) -> List[Tuple[str, float, int]]:\n",
    "        \"\"\"\n",
    "        Generate enhanced recommendations with confidence filtering\n",
    "        Returns: List of (product_id, predicted_rating, match_percentage)\n",
    "        \"\"\"\n",
    "        user_id = str(user_id)\n",
    "        user_rated = self.user_history_cache.get(user_id, {}).get('rated_products', [])\n",
    "        \n",
    "        all_products = self.prod_df[\"product_id\"].astype(str).tolist()\n",
    "        candidate_products = [pid for pid in all_products if pid not in user_rated]\n",
    "        \n",
    "        if not candidate_products:\n",
    "            return self._get_popular_fallback(top_n)\n",
    "        \n",
    "        recommendations = []\n",
    "        \n",
    "        for product_id in tqdm(candidate_products, desc=\"Predicting ratings\"):\n",
    "            try:\n",
    "                predicted_rating, confidence = self.hybrid_predict(user_id, product_id, content_weight, collab_weight)\n",
    "                match_percent = self.calculate_match_percentage(predicted_rating, user_id, product_id)\n",
    "                \n",
    "                if confidence >= min_confidence and match_percent >= 40:\n",
    "                    recommendations.append((product_id, predicted_rating, match_percent))\n",
    "            except Exception:\n",
    "                continue\n",
    "        \n",
    "        # ✅ Sort by hybrid predicted rating directly (no reranking)\n",
    "        recommendations.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        return recommendations[:top_n]\n",
    "\n",
    "    def _get_popular_fallback(self, top_n: int) -> List[Tuple[str, float, int]]:\n",
    "        \"\"\"Fallback to popular products\"\"\"\n",
    "        popular_products = self.test_df.groupby('product_id')['rating'].agg(['count', 'mean']).reset_index()\n",
    "        popular_products = popular_products[popular_products['count'] >= 10]  # Only reasonably popular\n",
    "        popular_products = popular_products.sort_values(['mean', 'count'], ascending=False)\n",
    "        \n",
    "        result = []\n",
    "        for _, row in popular_products.head(top_n).iterrows():\n",
    "            product_id = str(row['product_id'])\n",
    "            score = row['mean']\n",
    "            match_percent = self.calculate_match_percentage(score, \"average_user\", product_id)\n",
    "            result.append((product_id, score, match_percent))\n",
    "        \n",
    "        return result\n",
    "\n",
    "    def enhanced_demo_recommendations(self, user_id: str, top_n: int = 5,\n",
    "                                   content_weight: float = 0.4, collab_weight: float = 0.6):\n",
    "        \"\"\"Show enhanced recommendations with explanations\"\"\"\n",
    "        recommendations = self.generate_recommendations(user_id, top_n * 2, content_weight, collab_weight)\n",
    "        \n",
    "        print(f\"\\n🎯 ENHANCED RECOMMENDATIONS FOR USER {user_id}:\")\n",
    "        print(f\"   Weights: Content={content_weight}, SVD={collab_weight}\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        user_data = self.user_history_cache.get(str(user_id), {})\n",
    "        user_avg = user_data.get('avg_rating', self.global_avg)\n",
    "        \n",
    "        displayed = 0\n",
    "        for i, (product_id, score, match_percent) in enumerate(recommendations, 1):\n",
    "            if displayed >= top_n:\n",
    "                break\n",
    "                \n",
    "            product_info = self.prod_df[self.prod_df[\"product_id\"].astype(str) == product_id]\n",
    "            if product_info.empty:\n",
    "                continue\n",
    "                \n",
    "            product_info = product_info.iloc[0]\n",
    "            name = product_info[\"product_name\"]\n",
    "            brand = product_info[\"brand_name\"]\n",
    "            category = product_info[\"tertiary_category\"]\n",
    "            price = product_info[\"price_usd\"]\n",
    "            \n",
    "            formatted_price = f\"${price:.2f}\" if isinstance(price, (int, float)) else f\"${price}\"\n",
    "            \n",
    "            print(f\"{displayed + 1}. {name} ({brand})\")\n",
    "            print(f\"   📍 {category} • 💰 {formatted_price}\")\n",
    "            print(f\"   ⭐ {score:.4f}/5 • 🔍 {match_percent}% match\")\n",
    "            print(f\"   🆔 {product_id}\")\n",
    "            \n",
    "            # Add intelligent explanation\n",
    "            if score >= 4.2:\n",
    "                print(\"   💎 Excellent match! Based on your preferences and highly rated by similar users\")\n",
    "            elif score >= 3.8:\n",
    "                print(\"   👍 Great match - combines your product preferences with crowd wisdom\")\n",
    "            elif score >= 3.2:\n",
    "                print(\"   🔍 Good suggestion - users with similar tastes enjoyed this product\")\n",
    "            elif score >= 2.8:\n",
    "                print(\"   💡 Recommended - similar to products you've liked, worth exploring\")\n",
    "            else:\n",
    "                print(\"   🌟 New discovery - different from your usual preferences but highly rated\")\n",
    "            \n",
    "            print()\n",
    "            displayed += 1\n",
    "        \n",
    "        if displayed == 0:\n",
    "            print(\"⚠️  No confident recommendations found. Try rating more products!\")\n",
    "            print(\"💡 Exploring new categories might help improve recommendations\")\n",
    "        \n",
    "    def evaluate(self, top_n: int = 10,\n",
    "                content_weight: float = 0.4, collab_weight: float = 0.6,\n",
    "                min_confidence: float = 0.0) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Evaluate recommender on test dataset with multiple metrics:\n",
    "        - RMSE, MAE\n",
    "        - Accuracy (binary hit if predicted >= 3.5 matches actual >= 3.5)\n",
    "        - Precision, Recall, F1\n",
    "        - Coverage (how many unique products were recommended)\n",
    "        \"\"\"\n",
    "        print(\"\\n📊 Evaluating recommender system...\")\n",
    "\n",
    "        y_true, y_pred = [], []\n",
    "        hit_count, rec_count, relevant_count = 0, 0, 0\n",
    "        recommended_products = set()\n",
    "\n",
    "        for _, row in tqdm(self.test_df.iterrows(), total=len(self.test_df), desc=\"Evaluating\"):\n",
    "            user_id, product_id, actual_rating = str(row[\"author_id\"]), str(row[\"product_id\"]), row[\"rating\"]\n",
    "\n",
    "            try:\n",
    "                pred_rating, confidence = self.hybrid_predict(user_id, product_id,\n",
    "                                                            content_weight, collab_weight)\n",
    "                # if confidence < min_confidence:\n",
    "                #     continue\n",
    "\n",
    "                y_true.append(actual_rating)\n",
    "                y_pred.append(pred_rating)\n",
    "\n",
    "                # --- Binary relevance for classification metrics ---\n",
    "                actual_relevant = 1 if actual_rating >= 3.5 else 0\n",
    "                predicted_relevant = 1 if pred_rating >= 3.5 else 0\n",
    "\n",
    "                if predicted_relevant == 1:\n",
    "                    rec_count += 1\n",
    "                    recommended_products.add(product_id)\n",
    "\n",
    "                if actual_relevant == 1:\n",
    "                    relevant_count += 1\n",
    "\n",
    "                if predicted_relevant == 1 and actual_relevant == 1:\n",
    "                    hit_count += 1\n",
    "\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "        # --- Compute metrics ---\n",
    "        rmse = np.sqrt(mean_squared_error(y_true, y_pred)) if y_true else float(\"nan\")\n",
    "        mae = mean_absolute_error(y_true, y_pred) if y_true else float(\"nan\")\n",
    "        accuracy = accuracy_score([1 if r >= 3.5 else 0 for r in y_true],\n",
    "                                [1 if p >= 3.5 else 0 for p in y_pred]) if y_true else float(\"nan\")\n",
    "        precision = precision_score([1 if r >= 3.5 else 0 for r in y_true],\n",
    "                                    [1 if p >= 3.5 else 0 for p in y_pred],\n",
    "                                    zero_division=0) if y_true else float(\"nan\")\n",
    "        recall = recall_score([1 if r >= 3.5 else 0 for r in y_true],\n",
    "                            [1 if p >= 3.5 else 0 for p in y_pred],\n",
    "                            zero_division=0) if y_true else float(\"nan\")\n",
    "        f1 = f1_score([1 if r >= 3.5 else 0 for r in y_true],\n",
    "                    [1 if p >= 3.5 else 0 for p in y_pred],\n",
    "                    zero_division=0) if y_true else float(\"nan\")\n",
    "\n",
    "        coverage = len(recommended_products) / len(self.prod_df) if len(self.prod_df) > 0 else 0\n",
    "\n",
    "        results = {\n",
    "            \"RMSE\": rmse,\n",
    "            \"MAE\": mae,\n",
    "            \"Accuracy\": accuracy,\n",
    "            \"Precision\": precision,\n",
    "            \"Recall\": recall,\n",
    "            \"F1\": f1,\n",
    "            \"Coverage\": coverage\n",
    "        }\n",
    "\n",
    "        print(\"\\n📈 Evaluation Results:\")\n",
    "        for metric, value in results.items():\n",
    "            print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "        return results     \n",
    "    def evaluate_by_user_group(self, top_n=10):\n",
    "        \"\"\"\n",
    "        Evaluate recommender performance across user groups:\n",
    "        - Cold-start (<5 ratings)\n",
    "        - Medium (5-20 ratings)\n",
    "        - Heavy (>20 ratings)\n",
    "        \"\"\"\n",
    "        # Count ratings per user from training data\n",
    "        user_rating_counts = self.train_df.groupby(\"author_id\")[\"rating\"].count().to_dict()\n",
    "        \n",
    "        groups = {\n",
    "            \"Cold-start (<5)\": [],\n",
    "            \"Medium (5-20)\": [],\n",
    "            \"Heavy (>20)\": []\n",
    "        }\n",
    "\n",
    "        for _, row in self.test_df.iterrows():\n",
    "            user = str(row[\"author_id\"])\n",
    "            item = str(row[\"product_id\"])\n",
    "            true_rating = row[\"rating\"]\n",
    "\n",
    "            pred_rating, _ = self.hybrid_predict(user, item)\n",
    "\n",
    "            # Assign to group\n",
    "            count = user_rating_counts.get(user, 0)\n",
    "            if count < 5:\n",
    "                group = \"Cold-start (<5)\"\n",
    "            elif count > 20:\n",
    "                group = \"Heavy (>20)\"\n",
    "            else:\n",
    "                group = \"Medium (5-20)\"\n",
    "\n",
    "            groups[group].append((true_rating, pred_rating))\n",
    "\n",
    "        results = {}\n",
    "        for group, values in groups.items():\n",
    "            if not values:\n",
    "                continue\n",
    "            y_true, y_pred = zip(*values)\n",
    "            rmse = sqrt(mean_squared_error(y_true, y_pred))\n",
    "            mae = mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "            y_true_bin = [1 if r >= 4 else 0 for r in y_true]\n",
    "            y_pred_bin = [1 if p >= 4 else 0 for p in y_pred]\n",
    "\n",
    "            precision = precision_score(y_true_bin, y_pred_bin, zero_division=0)\n",
    "            recall = recall_score(y_true_bin, y_pred_bin, zero_division=0)\n",
    "            f1 = f1_score(y_true_bin, y_pred_bin, zero_division=0)\n",
    "            acc = accuracy_score(y_true_bin, y_pred_bin)\n",
    "\n",
    "            results[group] = {\n",
    "                \"RMSE\": rmse,\n",
    "                \"MAE\": mae,\n",
    "                \"Accuracy\": acc,\n",
    "                \"Precision\": precision,\n",
    "                \"Recall\": recall,\n",
    "                \"F1\": f1,\n",
    "                \"Count\": len(values)\n",
    "            }\n",
    "\n",
    "        results_df = pd.DataFrame(results).T\n",
    "        print(\"\\n📊 Evaluation by User Group:\")\n",
    "        print(results_df)\n",
    "        return results_df\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    print(\"🚀 INITIALIZING ENHANCED HYBRID RECOMMENDER\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # Initialize recommender\n",
    "    recommender = EnhancedHybridRecommender(\n",
    "        train_path=\"data/CleanedDataSet/train_skincare.csv\",\n",
    "        test_path=\"data/CleanedDataSet/test_skincare.csv\",\n",
    "        products_path=\"data/CleanedDataSet/filtered_skincare_products.csv\",\n",
    "        content_model_path=\"models/product_embeddings.pkl\",\n",
    "        svd_model_path=\"models/surprise_svd_model.pkl\"\n",
    "    )\n",
    "\n",
    "    print(\"\\n✅ ENHANCED INITIALIZATION COMPLETE!\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # 🔹 Fixed best weights for assignment\n",
    "    best_content_weight = 0.2\n",
    "    best_collab_weight = 0.8\n",
    "\n",
    "    # ---------------- 3) Generate recommendations for a real user ----------------\n",
    "    real_user_id = 2128891661  # <-- must exist in your dataset\n",
    "    recommender.enhanced_demo_recommendations(\n",
    "        user_id=real_user_id,\n",
    "        top_n=5,\n",
    "        content_weight=best_content_weight,\n",
    "        collab_weight=best_collab_weight\n",
    "    )\n",
    "\n",
    "    # ---------------- 4) Evaluate system ----------------\n",
    "    eval_results = recommender.evaluate(\n",
    "        top_n=10,\n",
    "        content_weight=best_content_weight,\n",
    "        collab_weight=best_collab_weight\n",
    "    )\n",
    "\n",
    "    # ---------------- 5) Evaluate by user groups ----------------\n",
    "    group_eval = recommender.evaluate_by_user_group()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2be7170",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
