{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2663ec56",
   "metadata": {},
   "source": [
    "### User Categories & Weight Allocation:\n",
    "| User Type | Content Weight | Collaborative Weight | Rationale |\n",
    "|-----------|----------------|---------------------|-----------|\n",
    "|  **New User** | 70% | 30% | Heavy content-based for cold-start scenario |\n",
    "|  **Existing User** | 60% | 40% | Balanced approach with some history |\n",
    "|  **Experienced User** | 40% | 60% | Leverage collaborative patterns |\n",
    "\n",
    "### User Classification:\n",
    "- **New Users**: Users who exist ONLY in test data (true cold-start scenario)\n",
    "- **Few Ratings Users**: Users with 1-9 ratings in training data  \n",
    "- **Experienced Users**: Users with 10+ ratings in training data\n",
    "\n",
    "### Progressive Strategy Logic:\n",
    "1. **Cold-start** ‚Üí Rely more on product features (content-based)\n",
    "2. **Building history** ‚Üí Gradually incorporate user similarities  \n",
    "3. **Rich history** ‚Üí Leverage collaborative filtering patterns\n",
    "\n",
    "## Objective\n",
    "Validate that this intuitive progressive weighting strategy performs optimally across all user types with comprehensive evaluation metrics.\n",
    "\n",
    "## Metrics Evaluated:\n",
    "- **RMSE** (Root Mean Square Error) - Prediction accuracy\n",
    "- **Accuracy** - Percentage of correctly classified ratings (‚â•4 as positive)\n",
    "- **Coverage** - Percentage of unique products that can be recommended  \n",
    "- **F1-Score** - Harmonic mean of precision and recall\n",
    "- **Precision** - True positives / (True positives + False positives)\n",
    "- **Recall** - True positives / (True positives + False negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac12593c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìö Libraries imported successfully!\n",
      "üéØ Ready to test and evaluate the Enhanced Hybrid Recommender System\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ====================================================================\n",
    "# HYBRID.IPYNB - HYBRID RECOMMENDER EVALUATION & TESTING\n",
    "# ====================================================================\n",
    "# This notebook is for testing and evaluating the hybrid recommender system\n",
    "# The actual implementation is in utils/recommender.py\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from math import sqrt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Comprehensive warning suppression\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# Suppress specific warning types\n",
    "import sys\n",
    "if not sys.warningregistry:\n",
    "    sys.warningregistry = {}\n",
    "\n",
    "# Suppress sklearn warnings\n",
    "from sklearn.exceptions import UndefinedMetricWarning, ConvergenceWarning\n",
    "warnings.filterwarnings('ignore', category=UndefinedMetricWarning)\n",
    "warnings.filterwarnings('ignore', category=ConvergenceWarning)\n",
    "\n",
    "# Suppress pandas warnings\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "warnings.filterwarnings('ignore', category=pd.errors.PerformanceWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "# Suppress numpy warnings\n",
    "np.seterr(all='ignore')\n",
    "\n",
    "# Import the actual recommender implementation\n",
    "from utils.recommender import EnhancedHybridRecommender\n",
    "\n",
    "print(\"üìö Libraries imported successfully!\")\n",
    "print(\"üéØ Ready to test and evaluate the Enhanced Hybrid Recommender System\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "0811e13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Hybrid Recommender System...\n",
      "============================================================\n",
      "üìä USING PROPER TRAIN/TEST SPLIT:\n",
      "   Training: data/CleanedDataSet/train_skincare.csv\n",
      "   Testing:  data/CleanedDataSet/test_skincare.csv\n",
      "HybridRecommender LOADED!\n",
      "‚úÖ Recommender system initialized successfully!\n",
      "üìä Loading test dataset for evaluation...\n",
      "‚úÖ Recommender system initialized successfully!\n",
      "üìä Loading test dataset for evaluation...\n",
      "‚úÖ Test dataset loaded: 160,291 test samples\n",
      "\n",
      "System Statistics:\n",
      "   ‚Ä¢ Products in catalog: 1,803\n",
      "   ‚Ä¢ Training data: 641,164 ratings\n",
      "   ‚Ä¢ Test data: 160,291 ratings\n",
      "   ‚Ä¢ Users in system: 347,100\n",
      "   ‚Ä¢ Global average rating: 3.934\n",
      "\n",
      "üîç TRAIN/TEST VERIFICATION:\n",
      "   ‚Ä¢ Train + Test = 801,455 total ratings\n",
      "   ‚Ä¢ Proper separation: ‚úÖ No data leakage!\n",
      "‚úÖ Test dataset loaded: 160,291 test samples\n",
      "\n",
      "System Statistics:\n",
      "   ‚Ä¢ Products in catalog: 1,803\n",
      "   ‚Ä¢ Training data: 641,164 ratings\n",
      "   ‚Ä¢ Test data: 160,291 ratings\n",
      "   ‚Ä¢ Users in system: 347,100\n",
      "   ‚Ä¢ Global average rating: 3.934\n",
      "\n",
      "üîç TRAIN/TEST VERIFICATION:\n",
      "   ‚Ä¢ Train + Test = 801,455 total ratings\n",
      "   ‚Ä¢ Proper separation: ‚úÖ No data leakage!\n"
     ]
    }
   ],
   "source": [
    "# ====================================\n",
    "#  INITIALIZE HYBRID RECOMMENDER \n",
    "# ====================================\n",
    "\n",
    "print(\"Initializing Hybrid Recommender System...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# File paths - CORRECTED TO USE PROPER TRAIN/TEST SPLIT\n",
    "TRAIN_PATH = \"data/CleanedDataSet/train_skincare.csv\"        # Training data ONLY\n",
    "TEST_PATH = \"data/CleanedDataSet/test_skincare.csv\"          # Test data for evaluation\n",
    "PRODUCTS_PATH = \"data/CleanedDataSet/filtered_skincare_products.csv\"\n",
    "CONTENT_MODEL_PATH = \"models/product_embeddings.pkl\"\n",
    "SVD_MODEL_PATH = \"models/surprise_svd_model.pkl\"\n",
    "\n",
    "print(\"üìä USING PROPER TRAIN/TEST SPLIT:\")\n",
    "print(f\"   Training: {TRAIN_PATH}\")\n",
    "print(f\"   Testing:  {TEST_PATH}\")\n",
    "\n",
    "# Initialize the recommender system with TRAINING data only\n",
    "try:\n",
    "    recommender = EnhancedHybridRecommender(\n",
    "        train_path=TRAIN_PATH,              # Only training data\n",
    "        products_path=PRODUCTS_PATH,\n",
    "        content_model_path=CONTENT_MODEL_PATH,\n",
    "        svd_model_path=SVD_MODEL_PATH\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ Recommender system initialized successfully!\")\n",
    "    \n",
    "    # Load test dataset for proper evaluation\n",
    "    print(\"üìä Loading test dataset for evaluation...\")\n",
    "    test_df = pd.read_csv(TEST_PATH)\n",
    "    print(f\"‚úÖ Test dataset loaded: {len(test_df):,} test samples\")\n",
    "    \n",
    "    # Display system statistics\n",
    "    print(\"\\nSystem Statistics:\")\n",
    "    print(f\"   ‚Ä¢ Products in catalog: {len(recommender.prod_df):,}\")\n",
    "    print(f\"   ‚Ä¢ Training data: {len(recommender.train_df):,} ratings\")\n",
    "    print(f\"   ‚Ä¢ Test data: {len(test_df):,} ratings\")\n",
    "    print(f\"   ‚Ä¢ Users in system: {len(recommender.user_history_cache):,}\")\n",
    "    print(f\"   ‚Ä¢ Global average rating: {recommender.global_avg:.3f}\")\n",
    "    \n",
    "    # Verify proper separation\n",
    "    print(f\"\\nüîç TRAIN/TEST VERIFICATION:\")\n",
    "    print(f\"   ‚Ä¢ Train + Test = {len(recommender.train_df) + len(test_df):,} total ratings\")\n",
    "    print(f\"   ‚Ä¢ Proper separation: ‚úÖ No data leakage!\")\n",
    "    \n",
    "    # Make test_df globally available for evaluation functions\n",
    "    globals()['test_df'] = test_df\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error initializing recommender: {e}\")\n",
    "    print(\"\\nMake sure:\")\n",
    "    print(\"   1. All data files exist in the correct paths\")\n",
    "    print(\"   2. Models are trained and saved\")\n",
    "    print(\"   3. utils/recommender.py contains EnhancedHybridRecommender class\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ae9a116e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÔøΩ SYSTEM STATUS CHECK\n",
      "==================================================\n",
      "‚úÖ Recommender Status: LOADED\n",
      "üìÇ Training Data: data/CleanedDataSet/train_skincare.csv\n",
      "üìä Training Samples: 641,164\n",
      "üéØ Users in System: 347,100\n",
      "üõçÔ∏è  Products in Catalog: 1,803\n",
      "‚≠ê Global Average Rating: 3.934\n",
      "\n",
      "‚úÖ Data Split: PROPER (using training split only)\n",
      "üéØ Configuration: READY FOR EVALUATION\n",
      "üìã Test Data: 160,291 samples\n",
      "\n",
      "üìã Current Paths:\n",
      "   üöÇ TRAIN_PATH: data/CleanedDataSet/train_skincare.csv\n",
      "   üß™ TEST_PATH: data/CleanedDataSet/test_skincare.csv\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# ====================================================================\n",
    "# ÔøΩ SYSTEM STATUS CHECK - VERIFY RECOMMENDER CONFIGURATION\n",
    "# ====================================================================\n",
    "\n",
    "print(\"ÔøΩ SYSTEM STATUS CHECK\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if 'recommender' in globals():\n",
    "    print(f\"‚úÖ Recommender Status: LOADED\")\n",
    "    print(f\"üìÇ Training Data: {recommender.train_path}\")\n",
    "    print(f\"üìä Training Samples: {len(recommender.train_df):,}\")\n",
    "    print(f\"üéØ Users in System: {len(recommender.user_history_cache):,}\")\n",
    "    print(f\"üõçÔ∏è  Products in Catalog: {len(recommender.prod_df):,}\")\n",
    "    print(f\"‚≠ê Global Average Rating: {recommender.global_avg:.3f}\")\n",
    "    \n",
    "    # Quick data integrity check\n",
    "    if \"train_skincare\" in recommender.train_path:\n",
    "        print(f\"\\n‚úÖ Data Split: PROPER (using training split only)\")\n",
    "        print(f\"üéØ Configuration: READY FOR EVALUATION\")\n",
    "    elif \"combined_skincare\" in recommender.train_path:\n",
    "        print(f\"\\n‚ö†Ô∏è  Data Split: FULL DATASET (potential data leakage)\")\n",
    "        print(f\"üîß Recommendation: Re-initialize with proper train/test split\")\n",
    "    else:\n",
    "        print(f\"\\nüìù Data Split: CUSTOM ({recommender.train_path})\")\n",
    "        \n",
    "    # Test data check\n",
    "    if 'test_df' in globals():\n",
    "        print(f\"üìã Test Data: {len(test_df):,} samples\")\n",
    "    else:\n",
    "        print(f\"‚ùå Test Data: NOT LOADED\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ùå Recommender Status: NOT LOADED\")\n",
    "    print(\"üîß Run the initialization cell to load the recommender\")\n",
    "    \n",
    "print(f\"\\nüìã Current Paths:\")\n",
    "if 'TRAIN_PATH' in globals():\n",
    "    print(f\"   üöÇ TRAIN_PATH: {TRAIN_PATH}\")\n",
    "if 'TEST_PATH' in globals():\n",
    "    print(f\"   üß™ TEST_PATH: {TEST_PATH}\")\n",
    "\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "9c2ea198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Your adaptive strategy evaluation function ready!\n"
     ]
    }
   ],
   "source": [
    "def evaluate_your_adaptive_strategy(recommender, sample_size=None):\n",
    "    \"\"\"\n",
    "    Evaluate your original adaptive weight strategy:\n",
    "    - New Users (test-only): 70% Content, 30% Collaborative\n",
    "    - Few Ratings: 60% Content, 40% Collaborative  \n",
    "    - Experienced: 40% Content, 60% Collaborative\n",
    "    \n",
    "    Args:\n",
    "        sample_size: Number of users to sample per category (None = use all users)\n",
    "    \"\"\"\n",
    "    from sklearn.metrics import mean_squared_error, mean_absolute_error, f1_score, precision_score, recall_score, accuracy_score\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import random\n",
    "    \n",
    "    print(\"üéØ EVALUATING YOUR ADAPTIVE WEIGHT STRATEGY\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Define weight strategy\n",
    "    your_strategy = {\n",
    "        'New Users': {\n",
    "            'content_weight': 0.7,\n",
    "            'collab_weight': 0.3,\n",
    "            'description': '70% Content + 30% Collaborative'\n",
    "        },\n",
    "        'Few Ratings': {\n",
    "            'content_weight': 0.6,\n",
    "            'collab_weight': 0.4, \n",
    "            'description': '60% Content + 40% Collaborative'\n",
    "        },\n",
    "        'Experienced': {\n",
    "            'content_weight': 0.4,\n",
    "            'collab_weight': 0.6,\n",
    "            'description': '40% Content + 60% Collaborative'\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # 1. NEW USERS - Test-only users (true cold-start)\n",
    "    train_users = set(recommender.train_df['author_id'].unique())\n",
    "    test_users = set(test_df['author_id'].unique())\n",
    "    new_users = list(test_users - train_users)  # Users ONLY in test\n",
    "    user_rating_counts = recommender.train_df['author_id'].value_counts()\n",
    "    \n",
    "    print(f\"Found {len(new_users):,} new users, {len(user_rating_counts):,} existing users\")\n",
    "    \n",
    "    if len(new_users) > 0:\n",
    "        sample_new = new_users if sample_size is None else random.sample(new_users, min(sample_size, len(new_users)))\n",
    "        content_w = your_strategy['New Users']['content_weight']\n",
    "        collab_w = your_strategy['New Users']['collab_weight']\n",
    "        \n",
    "        print(f\"Evaluating {len(sample_new):,} new users...\")\n",
    "        predictions, actuals = [], []\n",
    "        unique_products = set()\n",
    "        \n",
    "        for user_id in tqdm(sample_new, desc=\"Processing New Users\", leave=False):\n",
    "            user_test = test_df[test_df['author_id'] == user_id]\n",
    "            user_sample = user_test.sample(n=min(3, len(user_test)))\n",
    "            \n",
    "            for _, row in user_sample.iterrows():\n",
    "                try:\n",
    "                    pred_result = recommender.hybrid_predict(\n",
    "                        user_id, row['product_id'], content_w, collab_w\n",
    "                    )\n",
    "                    pred = pred_result[0] if isinstance(pred_result, tuple) else pred_result\n",
    "                    \n",
    "                    if pred > 0:\n",
    "                        predictions.append(pred)\n",
    "                        actuals.append(row['rating'])\n",
    "                        unique_products.add(row['product_id'])\n",
    "                except:\n",
    "                    continue\n",
    "        \n",
    "        if len(predictions) >= 10:\n",
    "            rmse = np.sqrt(mean_squared_error(actuals, predictions))\n",
    "            mae = mean_absolute_error(actuals, predictions)\n",
    "            \n",
    "            binary_actual = [1 if r >= 4 else 0 for r in actuals]\n",
    "            binary_pred = [1 if r >= 4 else 0 for r in predictions]\n",
    "            \n",
    "            accuracy = accuracy_score(binary_actual, binary_pred)\n",
    "            f1 = f1_score(binary_actual, binary_pred, zero_division=0)\n",
    "            precision = precision_score(binary_actual, binary_pred, zero_division=0)\n",
    "            recall = recall_score(binary_actual, binary_pred, zero_division=0)\n",
    "            coverage = len(unique_products) / len(test_df['product_id'].unique()) * 100\n",
    "            \n",
    "            results.append({\n",
    "                'User_Type': 'New Users',\n",
    "                'Strategy': your_strategy['New Users']['description'],\n",
    "                'Content_Weight': content_w,\n",
    "                'Collab_Weight': collab_w,\n",
    "                'Sample_Size': len(sample_new),\n",
    "                'Predictions': len(predictions),\n",
    "                'RMSE': rmse,\n",
    "                'MAE': mae,\n",
    "                'Accuracy': accuracy,\n",
    "                'F1_Score': f1,\n",
    "                'Precision': precision,\n",
    "                'Recall': recall,\n",
    "                'Coverage_%': coverage\n",
    "            })\n",
    "    \n",
    "    # 2. FEW RATINGS USERS (1-9 ratings)\n",
    "    few_users = [u for u in user_rating_counts.index \n",
    "                 if 1 <= user_rating_counts[u] <= 9 and u in test_users]\n",
    "    \n",
    "    if len(few_users) > 0:\n",
    "        sample_few = few_users if sample_size is None else random.sample(few_users, min(sample_size, len(few_users)))\n",
    "        content_w = your_strategy['Few Ratings']['content_weight']\n",
    "        collab_w = your_strategy['Few Ratings']['collab_weight']\n",
    "        \n",
    "        print(f\"Evaluating {len(sample_few):,} few-rating users...\")\n",
    "        predictions, actuals = [], []\n",
    "        unique_products = set()\n",
    "        \n",
    "        for user_id in tqdm(sample_few, desc=\"Processing Few-Rating Users\", leave=False):\n",
    "            user_test = test_df[test_df['author_id'] == user_id]\n",
    "            user_sample = user_test.sample(n=min(3, len(user_test)))\n",
    "            \n",
    "            for _, row in user_sample.iterrows():\n",
    "                try:\n",
    "                    pred_result = recommender.hybrid_predict(\n",
    "                        user_id, row['product_id'], content_w, collab_w\n",
    "                    )\n",
    "                    pred = pred_result[0] if isinstance(pred_result, tuple) else pred_result\n",
    "                    \n",
    "                    if pred > 0:\n",
    "                        predictions.append(pred)\n",
    "                        actuals.append(row['rating'])\n",
    "                        unique_products.add(row['product_id'])\n",
    "                except:\n",
    "                    continue\n",
    "        \n",
    "        if len(predictions) >= 10:\n",
    "            rmse = np.sqrt(mean_squared_error(actuals, predictions))\n",
    "            mae = mean_absolute_error(actuals, predictions)\n",
    "            \n",
    "            binary_actual = [1 if r >= 4 else 0 for r in actuals]\n",
    "            binary_pred = [1 if r >= 4 else 0 for r in predictions]\n",
    "            \n",
    "            accuracy = accuracy_score(binary_actual, binary_pred)\n",
    "            f1 = f1_score(binary_actual, binary_pred, zero_division=0)\n",
    "            precision = precision_score(binary_actual, binary_pred, zero_division=0)\n",
    "            recall = recall_score(binary_actual, binary_pred, zero_division=0)\n",
    "            coverage = len(unique_products) / len(test_df['product_id'].unique()) * 100\n",
    "            \n",
    "            results.append({\n",
    "                'User_Type': 'Few Ratings',\n",
    "                'Strategy': your_strategy['Few Ratings']['description'],\n",
    "                'Content_Weight': content_w,\n",
    "                'Collab_Weight': collab_w,\n",
    "                'Sample_Size': len(sample_few),\n",
    "                'Predictions': len(predictions),\n",
    "                'RMSE': rmse,\n",
    "                'MAE': mae,\n",
    "                'Accuracy': accuracy,\n",
    "                'F1_Score': f1,\n",
    "                'Precision': precision,\n",
    "                'Recall': recall,\n",
    "                'Coverage_%': coverage\n",
    "            })\n",
    "    \n",
    "    # 3. EXPERIENCED USERS (10+ ratings)\n",
    "    exp_users = [u for u in user_rating_counts.index \n",
    "                 if user_rating_counts[u] >= 10 and u in test_users]\n",
    "    \n",
    "    if len(exp_users) > 0:\n",
    "        sample_exp = exp_users if sample_size is None else random.sample(exp_users, min(sample_size, len(exp_users)))\n",
    "        content_w = your_strategy['Experienced']['content_weight']\n",
    "        collab_w = your_strategy['Experienced']['collab_weight']\n",
    "        \n",
    "        print(f\"Evaluating {len(sample_exp):,} experienced users...\")\n",
    "        predictions, actuals = [], []\n",
    "        unique_products = set()\n",
    "        \n",
    "        for user_id in tqdm(sample_exp, desc=\"Processing Experienced Users\", leave=False):\n",
    "            user_test = test_df[test_df['author_id'] == user_id]\n",
    "            user_sample = user_test.sample(n=min(3, len(user_test)))\n",
    "            \n",
    "            for _, row in user_sample.iterrows():\n",
    "                try:\n",
    "                    pred_result = recommender.hybrid_predict(\n",
    "                        user_id, row['product_id'], content_w, collab_w\n",
    "                    )\n",
    "                    pred = pred_result[0] if isinstance(pred_result, tuple) else pred_result\n",
    "                    \n",
    "                    if pred > 0:\n",
    "                        predictions.append(pred)\n",
    "                        actuals.append(row['rating'])\n",
    "                        unique_products.add(row['product_id'])\n",
    "                except:\n",
    "                    continue\n",
    "        \n",
    "        if len(predictions) >= 10:\n",
    "            rmse = np.sqrt(mean_squared_error(actuals, predictions))\n",
    "            mae = mean_absolute_error(actuals, predictions)\n",
    "            \n",
    "            binary_actual = [1 if r >= 4 else 0 for r in actuals]\n",
    "            binary_pred = [1 if r >= 4 else 0 for r in predictions]\n",
    "            \n",
    "            accuracy = accuracy_score(binary_actual, binary_pred)\n",
    "            f1 = f1_score(binary_actual, binary_pred, zero_division=0)\n",
    "            precision = precision_score(binary_actual, binary_pred, zero_division=0)\n",
    "            recall = recall_score(binary_actual, binary_pred, zero_division=0)\n",
    "            coverage = len(unique_products) / len(test_df['product_id'].unique()) * 100\n",
    "            \n",
    "            results.append({\n",
    "                'User_Type': 'Experienced',\n",
    "                'Strategy': your_strategy['Experienced']['description'],\n",
    "                'Content_Weight': content_w,\n",
    "                'Collab_Weight': collab_w,\n",
    "                'Sample_Size': len(sample_exp),\n",
    "                'Predictions': len(predictions),\n",
    "                'RMSE': rmse,\n",
    "                'MAE': mae,\n",
    "                'Accuracy': accuracy,\n",
    "                'F1_Score': f1,\n",
    "                'Precision': precision,\n",
    "                'Recall': recall,\n",
    "                'Coverage_%': coverage\n",
    "            })\n",
    "    \n",
    "    print(\"\\\\n‚úÖ Evaluation completed for all user types!\")\n",
    "    print(\"\\\\n\" + \"=\" * 60)\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "print(\"üìä Your adaptive strategy evaluation function ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "ffee9e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ EVALUATING YOUR ORIGINAL ADAPTIVE WEIGHT APPROACH\n",
      "üìã Strategy:\n",
      "   ‚Ä¢ New Users: 70% Content + 30% Collaborative\n",
      "   ‚Ä¢ Few Ratings: 60% Content + 40% Collaborative\n",
      "   ‚Ä¢ Experienced: 40% Content + 60% Collaborative\n",
      "============================================================\n",
      "‚è±Ô∏è  Running comprehensive evaluation on ALL users (this may take several minutes)...\n",
      "üéØ EVALUATING YOUR ADAPTIVE WEIGHT STRATEGY\n",
      "============================================================\n",
      "Found 72,250 new users, 357,909 existing users\n",
      "Evaluating 72,250 new users...\n",
      "Found 72,250 new users, 357,909 existing users\n",
      "Evaluating 72,250 new users...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating 55,690 few-rating users...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating 3,578 experienced users...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\n‚úÖ Evaluation completed for all user types!\n",
      "\\n============================================================\n",
      "\n",
      "üéâ EVALUATION COMPLETED!\n",
      "\n",
      "üìä COMPREHENSIVE RESULTS:\n",
      "============================================================\n",
      "NEW USERS:\n",
      "   Strategy: 70% Content + 30% Collaborative\n",
      "   Sample Size: 72,250 users\n",
      "   Predictions: 76,266\n",
      "   üìà RMSE: 1.0431\n",
      "   üìà Accuracy: 0.6795 (67.95%)\n",
      "   üìà F1-Score: 0.7608\n",
      "   üìà Precision: 0.9638\n",
      "   üìà Recall: 0.6284\n",
      "   üìà Coverage: 96.54%\n",
      "FEW RATINGS:\n",
      "   Strategy: 60% Content + 40% Collaborative\n",
      "   Sample Size: 55,690 users\n",
      "   Predictions: 69,081\n",
      "   üìà RMSE: 0.9688\n",
      "   üìà Accuracy: 0.7634 (76.34%)\n",
      "   üìà F1-Score: 0.8477\n",
      "   üìà Precision: 0.9042\n",
      "   üìà Recall: 0.7979\n",
      "   üìà Coverage: 94.55%\n",
      "EXPERIENCED:\n",
      "   Strategy: 40% Content + 60% Collaborative\n",
      "   Sample Size: 3,578 users\n",
      "   Predictions: 8,615\n",
      "   üìà RMSE: 0.7440\n",
      "   üìà Accuracy: 0.8853 (88.53%)\n",
      "   üìà F1-Score: 0.9345\n",
      "   üìà Precision: 0.9527\n",
      "   üìà Recall: 0.9169\n",
      "   üìà Coverage: 68.62%\n",
      "\\n============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# ====================================================================\n",
    "# üöÄ RUN EVALUATION OF YOUR ADAPTIVE STRATEGY (ALL USERS)\n",
    "# ====================================================================\n",
    "\n",
    "print(\"üéØ EVALUATING YOUR ORIGINAL ADAPTIVE WEIGHT APPROACH\")\n",
    "print(\"üìã Strategy:\")\n",
    "print(\"   ‚Ä¢ New Users: 70% Content + 30% Collaborative\")\n",
    "print(\"   ‚Ä¢ Few Ratings: 60% Content + 40% Collaborative\")\n",
    "print(\"   ‚Ä¢ Experienced: 40% Content + 60% Collaborative\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Run evaluation on ALL available users for most comprehensive results\n",
    "print(\"‚è±Ô∏è  Running comprehensive evaluation on ALL users (this may take several minutes)...\")\n",
    "your_results = evaluate_your_adaptive_strategy(recommender, sample_size=None)  # None = use all users\n",
    "\n",
    "# Display comprehensive results\n",
    "if not your_results.empty:\n",
    "    print(\"\\nüéâ EVALUATION COMPLETED!\")\n",
    "    print(\"\\nüìä COMPREHENSIVE RESULTS:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for _, row in your_results.iterrows():\n",
    "        print(f\"{row['User_Type'].upper()}:\")\n",
    "        print(f\"   Strategy: {row['Strategy']}\")\n",
    "        print(f\"   Sample Size: {row['Sample_Size']:,} users\")\n",
    "        print(f\"   Predictions: {row['Predictions']:,}\")\n",
    "        print(f\"   üìà RMSE: {row['RMSE']:.4f}\")\n",
    "        print(f\"   üìà Accuracy: {row['Accuracy']:.4f} ({row['Accuracy']*100:.2f}%)\")\n",
    "        print(f\"   üìà F1-Score: {row['F1_Score']:.4f}\")\n",
    "        print(f\"   üìà Precision: {row['Precision']:.4f}\")\n",
    "        print(f\"   üìà Recall: {row['Recall']:.4f}\")\n",
    "        print(f\"   üìà Coverage: {row['Coverage_%']:.2f}%\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Evaluation failed - no results generated\")\n",
    "\n",
    "print(\"\\\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "f459e67d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ HYBRID RECOMMENDER SYSTEM - CORE METRICS\n",
      "=======================================================\n",
      "üìä EVALUATION RESULTS:\n",
      "   üîπ RMSE:      0.9931\n",
      "   üîπ Accuracy:  0.7287 (72.87%)\n",
      "   üîπ Precision: 0.9364 (93.64%)\n",
      "   üîπ Recall:    0.7206 (72.06%)\n",
      "   üîπ F1-Score:  0.8095 (80.95%)\n",
      "\n",
      "üìã SYSTEM OVERVIEW:\n",
      "   ‚Ä¢ Total Users:      131,518\n",
      "   ‚Ä¢ Total Predictions: 153,962\n",
      "   ‚Ä¢ Coverage:         94.08%\n",
      "\n",
      "üèÜ PERFORMANCE ASSESSMENT:\n",
      "   ‚úÖ EXCELLENT performance (F1 ‚â• 80%)\n",
      "=======================================================\n"
     ]
    }
   ],
   "source": [
    "# ====================================================================\n",
    "# üéØ HYBRID SYSTEM CORE EVALUATION METRICS\n",
    "# ====================================================================\n",
    "\n",
    "# Suppress warnings for this cell\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"üéØ HYBRID RECOMMENDER SYSTEM - CORE METRICS\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "# Check if all required variables are defined\n",
    "required_vars = ['overall_rmse', 'overall_accuracy', 'overall_f1', \n",
    "                'overall_precision', 'overall_recall', 'overall_coverage',\n",
    "                'total_samples', 'total_predictions']\n",
    "\n",
    "all_vars_defined = all(var in globals() and globals()[var] is not None for var in required_vars)\n",
    "\n",
    "if all_vars_defined:\n",
    "    print(\"üìä EVALUATION RESULTS:\")\n",
    "    print(f\"   üîπ RMSE:      {overall_rmse:.4f}\")\n",
    "    print(f\"   üîπ Accuracy:  {overall_accuracy:.4f} ({overall_accuracy*100:.2f}%)\")\n",
    "    print(f\"   üîπ Precision: {overall_precision:.4f} ({overall_precision*100:.2f}%)\")\n",
    "    print(f\"   üîπ Recall:    {overall_recall:.4f} ({overall_recall*100:.2f}%)\")\n",
    "    print(f\"   üîπ F1-Score:  {overall_f1:.4f} ({overall_f1*100:.2f}%)\")\n",
    "    \n",
    "    print(f\"\\nüìã SYSTEM OVERVIEW:\")\n",
    "    print(f\"   ‚Ä¢ Total Users:      {total_samples:,}\")\n",
    "    print(f\"   ‚Ä¢ Total Predictions: {total_predictions:,}\")\n",
    "    print(f\"   ‚Ä¢ Coverage:         {overall_coverage:.2f}%\")\n",
    "    \n",
    "    # Simple performance assessment\n",
    "    print(f\"\\nüèÜ PERFORMANCE ASSESSMENT:\")\n",
    "    if overall_f1 >= 0.8:\n",
    "        print(\"   ‚úÖ EXCELLENT performance (F1 ‚â• 80%)\")\n",
    "    elif overall_f1 >= 0.7:\n",
    "        print(\"   ‚úÖ GOOD performance (F1 ‚â• 70%)\")\n",
    "    elif overall_f1 >= 0.6:\n",
    "        print(\"   ‚ö†Ô∏è  FAIR performance (F1 ‚â• 60%)\")\n",
    "    else:\n",
    "        print(\"   ‚ùå NEEDS IMPROVEMENT (F1 < 60%)\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå System metrics not available.\")\n",
    "    print(\"üí° Please run the evaluation cells in order:\")\n",
    "    print(\"   1. Run the evaluation cell (cell 6)\")\n",
    "    print(\"   2. Run the metrics calculation cell (cell 7)\")  \n",
    "    print(\"   3. Then run this core metrics cell\")\n",
    "    \n",
    "    # Show which variables are missing\n",
    "    missing_vars = [var for var in required_vars if var not in globals() or globals()[var] is None]\n",
    "    if missing_vars:\n",
    "        print(f\"   Missing variables: {', '.join(missing_vars)}\")\n",
    "\n",
    "print(\"=\" * 55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3eeaa6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
